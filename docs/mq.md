## 一.消息队列解决了哪些问题
通俗来说，消息队列的主要功能就是收发消息，但是它的作用不仅仅只是解决应用之间的通信问题这么简单。

日常开发中哪些问题适合使用消息队列来解决呢？

### 1.异步处理

就以前段时间面试最火的问题————如何设计一个秒杀系统举例。`秒杀系统需要解决的核心问题就是如何利用好有限的服务器资源，尽可能多地处理短时间内的海量的数据请求`。

一般秒杀请求包含以下几个步骤：
- 风险控制
- 库存锁定
- 生成订单
- 短信通知
- 更新统计数据

如果没有任何的优化的话，正常的处理流程就是：APP将请求发送给网关了，依次调用以上5个流程，然后将结果返回给APP.
对于这五个步骤来说，能否决定秒杀成功，实际上只有风险控制和库存锁定这两个步骤。只要用户的秒杀请求完成这两个步骤，对于后续的步骤，并不一定要在秒杀请求中处理完成，而是可以`将请求的数据放入消息队列中，有消息队列异步地进行后续的操作`，可以充分利用有限的服务资源处理更多真正的秒杀请求。

![Image text](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/miaosha.png)

优点：
- 更快地返回结果
- 减少等待，自然实现了步骤之间的并发，提升了系统总体的性能

### 2.流量控制
一个设计健壮的程序有自我保护能力，也就是说，它能够在海量的请求下，还能在自身能力范围内尽可能多地处理请求，拒绝处理不了请求并且保证自身正常运行。但是大多的程序并没有那么“健壮”，而直接拒绝请求返回错误对于用户来说体验也不好。

因此，需要设计一套健壮的架构来将后端的服务保护起来。一般的设计思路是： `使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的`。

加入消息队列后，整个秒杀流程变为：
- 1.网关在收到请求后，将请求放入消息队列中
- 2.后端服务从请求消息队列中获取APP请求，完成后续秒杀处理过程，然后返回结果。
![Image text](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq1.png)

秒杀开始后，当短时间内的大量秒杀请求到达网关后，不会直接冲击到后端的秒杀服务，而是先堆积在消息队列中，后端服务按照自己的最大处理能力，从消息队列中消费请求进行处理。

对于`超时`的请求可以直接丢弃，APP将超时无响应的请求处理为秒杀失败即可。运维人员还可以随时增加秒杀服务的实例数量进行水平扩容，而不用对系统的其他部分做任何的修改。

这样设计的优点就是：`能根据下游的处理能力自行调节流量，达到“削峰填谷”的作用`。

但是同样这种设计也有缺点：
- 增加了系统的调用链，导致总体的响应时间变长
- 上下游系统都要将同步调用调整为异步消息，增加了系统的复杂度。


除了上面的那种方式以外，还有相对简单的流量控制方法：如果可以预估出秒杀服务的处理能力，就可以用消息队列实现一个令牌桶，更加简单地进行流量控制。

令牌桶控制流量的原理就是：单位时间内只发放固定数量的令牌到令牌桶中，规定服务在处理请求之前必须从令牌桶中拿出一个令牌，如果令牌桶中没有令牌，则拒绝请求。这样就可以保证单位时间内请求的数量不会超过发放令牌的数量，起到了流量控制的作用。

![Image text](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq2.png)

其实现方式也很简单，不需要破坏原有的调用链，只要网关在处理APP请求时增加一个获取令牌的逻辑

令牌桶可以简单地用一个有固有容量的消息队列加一个“令牌发生器”来实现；令牌发生器按照预估的处理能力，均速生成令牌并放入令牌队列（如果队列满了则丢弃令牌），网关在收到请求时去令牌对列消费一个令牌。获取到令牌，获取到立牌则继续调用后端秒杀服务，如果获取不到令牌则直接返回秒杀失败。

### 3.服务解耦
消息队列还可以实现系统应用之间的解耦。

就以常见的电商项目为例，订单系统是比较核心的系统，当一个新的订单创建的时候
- 1.支付系统需要发起支付流程
- 2.风控系统需要审核订单的合法性
- 3.客服系统需要短息通知用户
- 4.运营分析系统需要更新数据
...

这些订单下游的系统都需要实时获得订单数据。随着业务不断发展，这些订单下游系统不断的增加，不断变化，并且每个系统可能只需要订单数据的一个子集，负责订单服务的开发团队不得不花费很大的精力，应对不断增加变化的下游系统，不停地修改调试订单系统与这些下游系统的接口。任何一个下游系统接口变更，都需要订单模块重新进行一次上线，对于一个电商的核心服务来说，这几乎是不可接受的。

所有的电商都选择用消息队列来解决类似的系统耦合过于紧密的问题。引入消息队列后，订单服务在订单变化时发送一条消息到消息队列的一个主题 Order 中，所有下游系统都订阅主题 Order，这样每个下游系统都可以获得一份实时完整的订单数据。

无论增加、减少下游系统或是下游系统需求如何变化，订单服务都无需做任何更改，实现了订单服务与下游服务的解耦。

### 其他
除了上面的三种最为常见的使用场景，还包括：
- 作为发布/订阅系统实现一个微服务级系统间的观察者模式；
- 连接流计算任务和数据
- 用于将消息广播给大量的接受者

简单的来说，我们在单体应用里面需要用到消息队列解决的问题，在分布式系统中大多数都可以用消息队列来解决

消息队列也有其自身的一些问题和局限性：
- 引入消息队列带来的延迟问题
- 增加了系统的复杂度
- 可能会出现数据一致性问题

## 二.如何选择消息队列
常见的消息队列中间件有很多，每一种产品都有自己的优缺点，所以就需要根据现有系统的情况，选择最合适的产品。
一个合格的消息队列中间件，必须具备一下几个特性：
- 消息可靠传递：确保不丢失消息；
- Cluster:支持集群，确保不会因为某个节点宕机导致服务不可用，本质上也是要保证消息不丢失；
- 性能：具备良好的性能，能够满足绝大多数场景下的性能要求。

### 常见的几种消息队列
- `RabbitMQ`

Erlang语言编写，是少数几个支持AMQP协议的消息队列之一。

Rabbit的宣传口号是：Messaging that just works ,"开箱即用的消息队列"。也就是说，`RabbitMQ是一个相当轻量级的消息队列，非常容易部署及使用`。

RabbitMQ 还有一个比较有特色的的功能就是支持非常灵活的路由配置，和其他消息队列不同的是，它在生产者（Producer）和队列（Queue）之间增加了一个Exchange模块，可以将其理解为交换机。

Exchange模块的作用和交换机也非常相似，根据配置的路由规则将生产者发出的消息分到不同的队列中。路由的规则也非常灵活，甚至可以自定义路由规则。

RabbitMQ客户端支持的编程语言大概是所有消息队列中最多的。

缺点：

**RabbitMQ对消息堆积的支持并不好，在它的设计理念中，消息队列是一个管道，大量的消息堆积是一种不正常的情况， 应当尽量的去避免。当大量的消息堆积时，会导致RabbitMQ的性能急剧下降。**

**RabbitMQ的性能相较于其他消息队列是最差的，大概每秒可以处理几万到几十万条消息，其实这个性能已经足够支撑绝大多数的应用场景了，但是，如果应用对消息队列的性能要求非常高的话，那就不要选择RabbitMQ。**

**RabbitMQ使用Erlang语言编写的，该语言难度较大，所以基于其做一些拓展或者二次开发，得慎重考虑维护问题。**


- `RocketMQ`

RocketMQ是阿里开源的消息队列产品，之后建赠与Apache软件基金会，有着不错的性能，稳定性和可靠性，具备一个现代消息队列应该有的几乎所有的功能和特性，并且他还在持续的成长中。

Rocket有非常活跃的中文社区，大多数的问题可以直接找到中文答案。此外，RocketMQ使用Java语言开发的，可以更容易对其进行二次开发或拓展。

RocketMQ对在线业务的响应延时做了很多的优化，大多数情况下都可以做到毫秒级的响应。如果应用场景很`在意响应延时`的话，就应该选择RocketMQ。

RocketMQ的性能比RabbitMQ要高出一个数量级，每秒钟大概可以处理几十万条消息。

RocketMQ的一个劣势就是作为国产的消息队列，相比于国外比较流行的同类产品，在国际上没那么流行，与周边生态系统的集成和兼容程度就要略逊一些了。

- `Kafka`

Kafka最早是由Linkedln开发，目前也是Apache的顶级项目，其最初设计目的在于处理海量的日志。

在早期Kafka为了获得极致的性能，在设计方面做出了很大的牺牲，比如不能保证消息的可靠性，可能会丢失消息，也不支持集群，功能上也比较简陋，这些牺牲对于处理海量日志这个特定的应用场景还是可以接受的。这个时期的Kafka甚至不能称为一个合格的消息队列。

但是，随着这几年Kafka的发展，当下Kafka已经是一个非常成熟的消息队列产品，无论在数据可靠性、稳定性和功能特性方面都可以满足绝大多数的场景需求。

kafka与周边生态系统的兼容性是最好的没有之一，尤其是在大数据和流计算领域，几乎所有的开源软件系统都会优先支持Kafka.

Kafka使用Scala和Java语言开发，设计上使用了批量和异步的思想，这种设计使得Kafka能够做到超高的性能。Kafka的性能，尤其是异步收发的性能，是三者中最好的，但是与RocketMQ并没有量级上的差异，大于每秒钟处理几十万条消息。

但是Kafka这种异步批量设计带来的问题可就是其`同步收发消息的响应延时较高`，因为当客户端发送一条消息的时候，Kafka并不会立即发送出去，而是`要等一会儿攒一批再发送`。所以当业务场景中每秒消息数量没有那么多时，Kafaka的时延反而会比较高。所以Kafka不太适合在线业务场景。

### 其他消息队列
ActiveMQ,老牌消息队列，与现代消息队列存在明显的差距,目前存在的意义就是兼容一些古老的系统。

ZeroMQ,严格来说它是一个基于消息队列的多线程网络库，如果需要消息队列的功能集成到系统进程中，可以考虑使用ZeroMQ。

Pulsar,新兴的开源消息队列产品，最早由Yahoo开发，目前处于成长期，流行度和成熟度相对没有那么高。与其他消息队列不同的是，Pulsar采用存储和计算分离的设计。

### 消息队列使用场景总结

系统对消息队列的功能和性能没有很高的要求，只需要一个开箱即用易于维护的产品，可以使用RabbitMQ。

系统使用消息队列的场景主要是处理在线业务，比如交易系统中用消息队列传递订单，可以使用RocketMQ，因为其低延迟和金融级的稳定性。

系统需要处理海量的消息，比如手机日志、监控信息或者前端的埋点这类数据，或是应用场景大量使用了大数据、流计算相关的开源产品，kafka是最适合的消息队列。

## 三.消息模型
每一款消息队列都有自己的一套消息模型，比如说队列（Queue）、主题（Topic）或者是分区（Partition）这些名词概念，在每个消息队列模型中都会涉及一些，含义还不太一样。

### 主题和队列有什么区别
最初的消息队列，就是一个严格意义上的队列。
> *队列是先进先出（FIFO, First-In-First-Out）的线性表（Linear List）。在具体应用中通常用链表或者数组来实现。队列只允许在后端（称为 rear）进行插入操作，在前端（称为 front）进行删除操作。*

在这个定义里面包含几个关键点，首先是先进先出，消息入队列的时候需要保证这些消息的严格有序，按照什么顺序进队列，必须按照同样的顺序从队列中读出来。但是队列是没有“读”这个操作的，“读”就是出队，也就是从队列中删除这条消息。

早期的消息队列近就是按照队列的数据结构设计的。生产者(Producer)发消息就是入队消息，消费者（Consumer）收消息就是出队也就是删除操作，服务端存放消息的容器自然就称为“队列”。

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq-model1.png)

如果有多个生产者往同一个队列中发送消息，这队列中可以消费到的消息，就是这些生产者的所有消息的合集。消息的顺序就是这些生产者发送消息的自然顺序。如果有多个消费者同时接受同一队列的消息，这些消费者之间实际上是竞争的关系，每个消费者只能收到队列中的一部分消息，也就是说任何一条消息只能被其中的一个消费者收到。

如果需要将一份消息数据分发给多个消费者，要求每个消费者都能收到全量的消息，例如，对于一份订单数据，风控系统、分析系统、支付系统等都需要就收消息。此时，单个队列就满足不了需求，一个可行的解决方法就是为每个消费者创建一个单独的队列，让生产者发送多份数。

但是这种方法显然是不合适的，同样一份消息数据被复制到多个队列中会浪费，更重要的是，生产这必须知道有多少个消费者。为每个消费者单独发送一份消息，这实际上违背了消息队列“解耦”这个设计初衷。

为了解决这一问题，演化了另外一种消息模型：“发布-订阅模型（Publish-Subscribe Pattern）”

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq-model02.png)

在发布-订阅模型中，消息的发送方称为发布者（Publisher），消息的接收方称为订阅者（Subsrciber），服务端存放消息的容器称为`主题（Topic）`，发布者将消息发送到主题中，订阅者在接受消息之前需要先“订阅主题”。“订阅”既是一个动作，同时还可以认为是主题在消费时的一个逻辑副本，每份订阅中，订阅者都可以接收到主题的所有消息。

在消息领域的历史上很长一段时间，队列模式和发布-订阅模式是并存的，有些消息队列同时支持这两种消息模型，比如ActiveMQ。仔细对比一下这两种模型，生产者就是发布者，消费者就是订阅者，队列就是主题，并没有本质的区别。它们最大的区别就是一份消息能不能被消费多次的问题。

实际上，在这种发布-订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。也就是说，发布-订阅模型在功能层面上是可以兼容队列模型的。

现代的消息队列产品使用的消息模型大多数是发布-订阅模型，当然也有一些例外，比如RabbitMQ。

### RabbitMQ 的消息模型
RabbitMQ是少数依然坚持使用队列模型的产品之一。RabbitMQ的Exchange模块位于生产者和队列中间，生产者并不关心将消息发送给哪个队列，而是将消息发送Exchage,由Exchange上配置的策略来决定将消息投递到哪个队列中。
![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq03.png)

同一份消息如果需要被多个消费者来消费，需要配置Exchange将消息发送到多个队列，每个队列中都存放一份完整的消息数据，可以为一个消费者提供消费服务。这也可以变相的实现“发布-订阅模型”中一份消息可以被多个订阅者来多次消费的功能。

### RocketMQ 的消息模型
Rocket使用的消息模型是标准的发布订阅模型。但是RocketMQ也有队列（Queue）这个概念，并且队列在RocketMQ中是一个非常重要的概念，那队列在RokcetMQ中的作用是什么呢？这就要从消息队列的消费机制说起。

几乎所有的消息队列产品都使用一种非常朴素的`“请求-确认”`机制，确保消息不会在传递过程中由于网络或者服务器故障丢失。具体的做法非常简单，在生产端，生产者现将消息发给服务端，也就是Broker，服务端在收到消息并将消息写入主题或队列中后，会给发送者发送确认的响应。

如果生产者没有收到服务端的确认或者收到失败的响应，则会重新发送消息；在消费端，消费者在收到消息并完成自己的消费业务逻辑（比如进行减库存操作）后，也会给服务端发送消费成功的确认，服务端只有收到消费确认后，才认为一条消息被成功消费，否则它会给消费者重新发送这条消息，直到收到对应的消费成功确认。

这个机制很好的确保了消息传递过程中的可靠性，但是，引入这个机制给消费端带来了一个不小的问题：为了确保消息的有序性，在某一条消息被成功消费之前，下一条消息是不能被消费的，否则会出现消息空洞，违背了有序性这个原则。

也就是说，每个主题在任意时刻，至多只有一个消费者实例在进行消费，那就无法通过水平拓展消费者的数量来提升消费端总体的性能，为了解决这个问题，RocketMQ在主题下面增加了队列的概念。

**每个主题包含多个对垒，通过多个队列来实现多实例并行生产和消费。**需要注意的是，RocketMQ只在队列上保证消息的有序性，主题层面上无法保证消息的严格顺序。

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq04.png)

RocketMQ中，订阅者的概念是通过订阅组（Consumer Group）来体现的。每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响，也就是说，一条消息被Consumer Group1消费过，也会再给Consumer Group2消费。

消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者杜负责消费组内的一部分消息。如果一条消息被消费者Consumer1消费了，那同组的其他消费者就不会再收到这条消息。

在Topic的消费过程中，由于消息需要被不用的组进行多次消费，所以消费完的消息并不会被立即删除，这就需要RocketMQ为每一个消费组在每个队列上维护一个消费位置（Consumer Offset），这个位置之前是的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。这个消费位置是非常重要的概念，`在使用消费队列的时候，丢消息的原因大多数是应为消费位置处理不当导致的。`

### Kafka的消息模型
Kafka的消息模型与RockeMQ是一致的。唯一的区别就是队列这个名称在Kafka中称为“分区（Partition）”，含义和功能上是没有任何区别的。

## 四.利用消息队列实现分布式事务

在日常是使用事务的场景，无外乎就是在操作数据库的时候。像MySQL,Oracle 这些主流的关系型数据库，也都提供的完整的事务实现。那消息队列为什么也需要事务呢？

其实在很多场景下，我们发消息这个过程，目的往往就是通知另外一个系统或模块去更新数据，`消息队列中的事务，主要解决的就是消息生产者和消息消费者的数据一致性问题。`

就以电商项目为例。订单系统创建订单后，发消息给购物车系统，将已下单的商品从购物车中删除，因为从购物车中删除已下单的商品这个步骤，并不是用户下单支付这个主要流程中的必需的步骤，使用消息队列来异步清除购物车是更加合理的设计。
![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq05.png)

对于订单系统来说，创建订单的过程中实际上是执行了2个步骤的操作：
- 1.在订单库中插入一条订单数据，创建订单；
- 2.发消息给消息队列，消息的内容就是刚刚创建的订单。

购物车系统订阅相应的主题，接受订单创建的消息，然后清理购物车，在购物车中删除订单中的商品。

在分布式系统总，上面提到的这些步骤，任何一个步骤都有可能失败，如果不做任何处理，那么就可能出现订单数据和购物车数据不一致的情况，例如：
- 创建了订单并没有清理购物车；
- 订单没创建成功，购物车里面的商品却被清掉了。

需要解决的问题可以总结为：在上述任一步骤都有可能失败的情况下，还要保证订单库和购物车库这两个库的数据的一致性。

对于购物车系统收到订单创建成功消息清理购物车这个操作来说，失败的处理比较简单，只要成功执行购物车清理后再提交消费确认即可，如果失败，由于没有提交消费确认，消息队列就会自动重试。

问题的关键点集中在订单系统，创建订单和发送消息这两个步骤要么都操作成功，要么都操作失败，不允许一个成功一个失败的情况出现。

### 什么是分布式事务

如果我们需要对若干数据进行更新操作，为了保证这些数据的完整性和一致性，我们希望这些更新操作`要么都成功，要么都失败`。至于更新的数据，不只局限于数据库中的数据，也可能是磁盘上的一个文件，也可以是远端的一个服务，或者以其他形式存储的数据。

一个严格意义的事务实现，应该具有4个属性：`原子性`、`一致性`、`隔离性`和`持久性`。（ACID）
- 原子性：是指一个事务的操作不可分割，要么失败，要么成功，不能有一般成功一半失败的情况。
- 一致性:是指这些数据在事务执行完成这个时间点之前，读到的一定是更新前的数据，之后读到的一定是更新后的数据，不应该存在一个时刻，让用户读到更新过程中的数据。
- 隔离性：是指一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对正在进行的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。
- 持久性：是指一个事务一旦提交，后续的其他操作和故障都不会对事务的结果产生任何影响。

大部分传统的单体关系型数据库都完整的实现了ACID,但是，对于分布式系统来说，严格的实现ACID这四个特性几乎是不可能的，或者是实现的代价太大。

目前大家所说的分布式事务，更多情况下，是在分布式系统中事物的不完整实现。在不同的应用场景中，有不同的实现，目的是通过一些妥协来解决方案。

在实际的应用中，比较常见的分布式事务实现由 `2PC(Two-phase Commit，也叫做二阶段提交)`、`TCC(Try-Confirm-Cancel)`和`事务消息`。每一种实现都有其特定的使用场景，也有各自的问题，都不是完美的解决方案。

事务消息使用的场景主要是那些需要`异步更新数据`，并且对`数据实时性要求不太高的场景`。比如之前的例子，创建订单之后，如果出现短暂的几秒，购物车中的商品被没有及时清空，也不是完全不可以接受的，只是最终购物车的数据和订单数据保持一致就可以了。

### 消息队列是如何实现分布式事务的

事务消息需要消息队列提供相应的功能才能实现，Kafka和RocketMQ都提供了事务相关的功能。

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq06.png)

首先，订单系统在消息队列中开启一个事务，然后订单系统给消息服务器发送一个`“半消息”`，这个半消息并不是说消息是不完整的，它包含的内容就是完整的消息内容，半消息和普通消息的唯一区别是，在事务提交之前，对于消费者来说，这个消息是不可见的。

半消息发送成功之后，订单系统就可以执行本地事务了，在订单库中创建一条订单记录，并提交订单库的数据库事务。然后根据本地事务的执行结果提交或回滚事务消息。如果订单创建成功，那就提交事务消息，购物车系统就可以消费到这条消息然后继续后续的流程；如果订单创建失败，那就回滚事务消息，购物车系统就不会收到这条消息。n那么就基本实现了“要么都成功，要么都失败”的一致性要求。

但是，如果仅仅只是这样做还是有问题没有解决。如果在第四步提交事务消息失败了怎么办？kafka和RocketMQ给出了不同的解决方法。

Kafka的解决方案比较简单粗暴，直接抛出异常，让用户自行解决，我们可以在业务代码中重试提交，直到提交成功，或者也可以在删除之前创建的订单进行补偿。

**RocketMQ中分布式事务实现**
