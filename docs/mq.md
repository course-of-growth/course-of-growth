## 一.消息队列解决了哪些问题
通俗来说，消息队列的主要功能就是收发消息，但是它的作用不仅仅只是解决应用之间的通信问题这么简单。

日常开发中哪些问题适合使用消息队列来解决呢？

### 1.异步处理

就以前段时间面试最火的问题————如何设计一个秒杀系统举例。`秒杀系统需要解决的核心问题就是如何利用好有限的服务器资源，尽可能多地处理短时间内的海量的数据请求`。

一般秒杀请求包含以下几个步骤：
- 风险控制
- 库存锁定
- 生成订单
- 短信通知
- 更新统计数据

如果没有任何的优化的话，正常的处理流程就是：APP将请求发送给网关了，依次调用以上5个流程，然后将结果返回给APP.
对于这五个步骤来说，能否决定秒杀成功，实际上只有风险控制和库存锁定这两个步骤。只要用户的秒杀请求完成这两个步骤，对于后续的步骤，并不一定要在秒杀请求中处理完成，而是可以`将请求的数据放入消息队列中，有消息队列异步地进行后续的操作`，可以充分利用有限的服务资源处理更多真正的秒杀请求。

![Image text](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/miaosha.png)

优点：
- 更快地返回结果
- 减少等待，自然实现了步骤之间的并发，提升了系统总体的性能

### 2.流量控制
一个设计健壮的程序有自我保护能力，也就是说，它能够在海量的请求下，还能在自身能力范围内尽可能多地处理请求，拒绝处理不了请求并且保证自身正常运行。但是大多的程序并没有那么“健壮”，而直接拒绝请求返回错误对于用户来说体验也不好。

因此，需要设计一套健壮的架构来将后端的服务保护起来。一般的设计思路是： `使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的`。

加入消息队列后，整个秒杀流程变为：
- 1.网关在收到请求后，将请求放入消息队列中
- 2.后端服务从请求消息队列中获取APP请求，完成后续秒杀处理过程，然后返回结果。
![Image text](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq1.png)

秒杀开始后，当短时间内的大量秒杀请求到达网关后，不会直接冲击到后端的秒杀服务，而是先堆积在消息队列中，后端服务按照自己的最大处理能力，从消息队列中消费请求进行处理。

对于`超时`的请求可以直接丢弃，APP将超时无响应的请求处理为秒杀失败即可。运维人员还可以随时增加秒杀服务的实例数量进行水平扩容，而不用对系统的其他部分做任何的修改。

这样设计的优点就是：`能根据下游的处理能力自行调节流量，达到“削峰填谷”的作用`。

但是同样这种设计也有缺点：
- 增加了系统的调用链，导致总体的响应时间变长
- 上下游系统都要将同步调用调整为异步消息，增加了系统的复杂度。


除了上面的那种方式以外，还有相对简单的流量控制方法：如果可以预估出秒杀服务的处理能力，就可以用消息队列实现一个令牌桶，更加简单地进行流量控制。

令牌桶控制流量的原理就是：单位时间内只发放固定数量的令牌到令牌桶中，规定服务在处理请求之前必须从令牌桶中拿出一个令牌，如果令牌桶中没有令牌，则拒绝请求。这样就可以保证单位时间内请求的数量不会超过发放令牌的数量，起到了流量控制的作用。

![Image text](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq2.png)

其实现方式也很简单，不需要破坏原有的调用链，只要网关在处理APP请求时增加一个获取令牌的逻辑

令牌桶可以简单地用一个有固有容量的消息队列加一个“令牌发生器”来实现；令牌发生器按照预估的处理能力，均速生成令牌并放入令牌队列（如果队列满了则丢弃令牌），网关在收到请求时去令牌对列消费一个令牌。获取到令牌，获取到立牌则继续调用后端秒杀服务，如果获取不到令牌则直接返回秒杀失败。

### 3.服务解耦
消息队列还可以实现系统应用之间的解耦。

就以常见的电商项目为例，订单系统是比较核心的系统，当一个新的订单创建的时候
- 1.支付系统需要发起支付流程
- 2.风控系统需要审核订单的合法性
- 3.客服系统需要短息通知用户
- 4.运营分析系统需要更新数据
...

这些订单下游的系统都需要实时获得订单数据。随着业务不断发展，这些订单下游系统不断的增加，不断变化，并且每个系统可能只需要订单数据的一个子集，负责订单服务的开发团队不得不花费很大的精力，应对不断增加变化的下游系统，不停地修改调试订单系统与这些下游系统的接口。任何一个下游系统接口变更，都需要订单模块重新进行一次上线，对于一个电商的核心服务来说，这几乎是不可接受的。

所有的电商都选择用消息队列来解决类似的系统耦合过于紧密的问题。引入消息队列后，订单服务在订单变化时发送一条消息到消息队列的一个主题 Order 中，所有下游系统都订阅主题 Order，这样每个下游系统都可以获得一份实时完整的订单数据。

无论增加、减少下游系统或是下游系统需求如何变化，订单服务都无需做任何更改，实现了订单服务与下游服务的解耦。

### 其他
除了上面的三种最为常见的使用场景，还包括：
- 作为发布/订阅系统实现一个微服务级系统间的观察者模式；
- 连接流计算任务和数据
- 用于将消息广播给大量的接受者

简单的来说，我们在单体应用里面需要用到消息队列解决的问题，在分布式系统中大多数都可以用消息队列来解决

消息队列也有其自身的一些问题和局限性：
- 引入消息队列带来的延迟问题
- 增加了系统的复杂度
- 可能会出现数据一致性问题

参考：
```
Understanding When to use RabbitMQ or Apache Kafka ，什么时候使用 RabbitMQ，什么时候使用 Kafka，通过这篇文章可以让你明白如何做技术决策。
Trello: Why We Chose Kafka For The Trello Socket Architecture ，Trello 的 Kafka 架构分享。
LinkedIn: Running Kafka At Scale ，LinkedIn 公司的 Kafka 架构扩展实践。
Should You Put Several Event Types in the Same Kafka Topic? ，这个问题可能经常困扰你，这篇文章可以为你找到答案。
Billions of Messages a Day - Yelp’s Real-time Data Pipeline ，Yelp 公司每天十亿级实时消息的架构。
Uber: Building Reliable Reprocessing and Dead Letter Queues with Kafka ，Uber 公司的 Kafka 应用。
Uber: Introducing Chaperone: How Uber Engineering Audits Kafka End-to-End ，Uber 公司对 Kafka 消息的端到端审计。
Publishing with Apache Kafka at The New York Times ，纽约时报的 Kafka 工程实践。
Kafka Streams on Heroku ，Heroku 公司的 Kafka Streams 实践。
Salesforce: How Apache Kafka Inspired Our Platform Events Architecture ，Salesforce 的 Kafka 工程实践。
Exactly-once Semantics are Possible: Here’s How Kafka Does it ，怎样用 Kafka 让只发送一次的语义变为可能。这是业界中一个很难的工程问题。
Delivering billions of messages exactly once 同上，这也是一篇挑战消息只发送一次这个技术难题的文章。
Benchmarking Streaming Computation Engines at Yahoo!。Yahoo! 的 Storm 团队在为他们的流式计算做技术选型时，发现市面上缺乏针对不同计算平台的性能基准测试。于是，他们研究并设计了一种方案来做基准测试，测试了 Apache Flink、Apache Storm 和 Apache Spark 这三种平台。文中给出了结论和具体的测试方案。（如果原文链接不可用，请尝试搜索引擎对该网页的快照。） 
```

## 二.如何选择消息队列
常见的消息队列中间件有很多，每一种产品都有自己的优缺点，所以就需要根据现有系统的情况，选择最合适的产品。
一个合格的消息队列中间件，必须具备一下几个特性：
- 消息可靠传递：确保不丢失消息；
- Cluster:支持集群，确保不会因为某个节点宕机导致服务不可用，本质上也是要保证消息不丢失；
- 性能：具备良好的性能，能够满足绝大多数场景下的性能要求。

### 常见的几种消息队列
- `RabbitMQ`

Erlang语言编写，是少数几个支持AMQP协议的消息队列之一。

Rabbit的宣传口号是：Messaging that just works ,"开箱即用的消息队列"。也就是说，`RabbitMQ是一个相当轻量级的消息队列，非常容易部署及使用`。

RabbitMQ 还有一个比较有特色的的功能就是支持非常灵活的路由配置，和其他消息队列不同的是，它在生产者（Producer）和队列（Queue）之间增加了一个Exchange模块，可以将其理解为交换机。

Exchange模块的作用和交换机也非常相似，根据配置的路由规则将生产者发出的消息分到不同的队列中。路由的规则也非常灵活，甚至可以自定义路由规则。

RabbitMQ客户端支持的编程语言大概是所有消息队列中最多的。

缺点：

**RabbitMQ对消息堆积的支持并不好，在它的设计理念中，消息队列是一个管道，大量的消息堆积是一种不正常的情况， 应当尽量的去避免。当大量的消息堆积时，会导致RabbitMQ的性能急剧下降。**

**RabbitMQ的性能相较于其他消息队列是最差的，大概每秒可以处理几万到几十万条消息，其实这个性能已经足够支撑绝大多数的应用场景了，但是，如果应用对消息队列的性能要求非常高的话，那就不要选择RabbitMQ。**

**RabbitMQ使用Erlang语言编写的，该语言难度较大，所以基于其做一些拓展或者二次开发，得慎重考虑维护问题。**


- `RocketMQ`

RocketMQ是阿里开源的消息队列产品，之后建赠与Apache软件基金会，有着不错的性能，稳定性和可靠性，具备一个现代消息队列应该有的几乎所有的功能和特性，并且他还在持续的成长中。

RocketMQ有非常活跃的中文社区，大多数的问题可以直接找到中文答案。此外，RocketMQ使用Java语言开发的，可以更容易对其进行二次开发或拓展。

RocketMQ对在线业务的响应延时做了很多的优化，大多数情况下都可以做到毫秒级的响应。如果应用场景很`在意响应延时`的话，就应该选择RocketMQ。

RocketMQ的性能比RabbitMQ要高出一个数量级，每秒钟大概可以处理几十万条消息。

RocketMQ的一个劣势就是作为国产的消息队列，相比于国外比较流行的同类产品，在国际上没那么流行，与周边生态系统的集成和兼容程度就要略逊一些了。

- `Kafka`

Kafka最早是由Linkedln开发，目前也是Apache的顶级项目，其最初设计目的在于处理海量的日志。

在早期Kafka为了获得极致的性能，在设计方面做出了很大的牺牲，比如不能保证消息的可靠性，可能会丢失消息，也不支持集群，功能上也比较简陋，这些牺牲对于处理海量日志这个特定的应用场景还是可以接受的。这个时期的Kafka甚至不能称为一个合格的消息队列。

但是，随着这几年Kafka的发展，当下Kafka已经是一个非常成熟的消息队列产品，无论在数据可靠性、稳定性和功能特性方面都可以满足绝大多数的场景需求。

kafka与周边生态系统的兼容性是最好的没有之一，尤其是在大数据和流计算领域，几乎所有的开源软件系统都会优先支持Kafka.

Kafka使用Scala和Java语言开发，设计上使用了批量和异步的思想，这种设计使得Kafka能够做到超高的性能。Kafka的性能，尤其是异步收发的性能，是三者中最好的，但是与RocketMQ并没有量级上的差异，大于每秒钟处理几十万条消息。

但是Kafka这种异步批量设计带来的问题可就是其`同步收发消息的响应延时较高`，因为当客户端发送一条消息的时候，Kafka并不会立即发送出去，而是`要等一会儿攒一批再发送`。所以当业务场景中每秒消息数量没有那么多时，Kafaka的时延反而会比较高。所以Kafka不太适合在线业务场景。

### 其他消息队列
ActiveMQ,老牌消息队列，与现代消息队列存在明显的差距,目前存在的意义就是兼容一些古老的系统。

ZeroMQ,严格来说它是一个基于消息队列的多线程网络库，如果需要消息队列的功能集成到系统进程中，可以考虑使用ZeroMQ。

Pulsar,新兴的开源消息队列产品，最早由Yahoo开发，目前处于成长期，流行度和成熟度相对没有那么高。与其他消息队列不同的是，Pulsar采用存储和计算分离的设计。

### 消息队列使用场景总结

系统对消息队列的功能和性能没有很高的要求，只需要一个开箱即用易于维护的产品，可以使用RabbitMQ。

系统使用消息队列的场景主要是处理在线业务，比如交易系统中用消息队列传递订单，可以使用RocketMQ，因为其低延迟和金融级的稳定性。

系统需要处理海量的消息，比如手机日志、监控信息或者前端的埋点这类数据，或是应用场景大量使用了大数据、流计算相关的开源产品，kafka是最适合的消息队列。 	 	 	 
 	 	 	 	 	 
参考地址  ：https://blog.csdn.net/belvine/article/details/80842240   

 

## 三.消息模型
每一款消息队列都有自己的一套消息模型，比如说队列（Queue）、主题（Topic）或者是分区（Partition）这些名词概念，在每个消息队列模型中都会涉及一些，含义还不太一样。

### 主题和队列有什么区别
最初的消息队列，就是一个严格意义上的队列。
> *队列是先进先出（FIFO, First-In-First-Out）的线性表（Linear List）。在具体应用中通常用链表或者数组来实现。队列只允许在后端（称为 rear）进行插入操作，在前端（称为 front）进行删除操作。*

在这个定义里面包含几个关键点，首先是先进先出，消息入队列的时候需要保证这些消息的严格有序，按照什么顺序进队列，必须按照同样的顺序从队列中读出来。但是队列是没有“读”这个操作的，“读”就是出队，也就是从队列中删除这条消息。

早期的消息队列近就是按照队列的数据结构设计的。生产者(Producer)发消息就是入队消息，消费者（Consumer）收消息就是出队也就是删除操作，服务端存放消息的容器自然就称为“队列”。

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq-model1.png)

如果有多个生产者往同一个队列中发送消息，这队列中可以消费到的消息，就是这些生产者的所有消息的合集。消息的顺序就是这些生产者发送消息的自然顺序。如果有多个消费者同时接受同一队列的消息，这些消费者之间实际上是竞争的关系，每个消费者只能收到队列中的一部分消息，也就是说任何一条消息只能被其中的一个消费者收到。

如果需要将一份消息数据分发给多个消费者，要求每个消费者都能收到全量的消息，例如，对于一份订单数据，风控系统、分析系统、支付系统等都需要就收消息。此时，单个队列就满足不了需求，一个可行的解决方法就是为每个消费者创建一个单独的队列，让生产者发送多份数。

但是这种方法显然是不合适的，同样一份消息数据被复制到多个队列中会浪费，更重要的是，生产这必须知道有多少个消费者。为每个消费者单独发送一份消息，这实际上违背了消息队列“解耦”这个设计初衷。

为了解决这一问题，演化了另外一种消息模型：“发布-订阅模型（Publish-Subscribe Pattern）”

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq-model02.png)

在发布-订阅模型中，消息的发送方称为发布者（Publisher），消息的接收方称为订阅者（Subsrciber），服务端存放消息的容器称为`主题（Topic）`，发布者将消息发送到主题中，订阅者在接受消息之前需要先“订阅主题”。“订阅”既是一个动作，同时还可以认为是主题在消费时的一个逻辑副本，每份订阅中，订阅者都可以接收到主题的所有消息。

在消息领域的历史上很长一段时间，队列模式和发布-订阅模式是并存的，有些消息队列同时支持这两种消息模型，比如ActiveMQ。仔细对比一下这两种模型，生产者就是发布者，消费者就是订阅者，队列就是主题，并没有本质的区别。它们最大的区别就是一份消息能不能被消费多次的问题。

实际上，在这种发布-订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。也就是说，发布-订阅模型在功能层面上是可以兼容队列模型的。

现代的消息队列产品使用的消息模型大多数是发布-订阅模型，当然也有一些例外，比如RabbitMQ。

### RabbitMQ 的消息模型
RabbitMQ是少数依然坚持使用队列模型的产品之一。RabbitMQ的Exchange模块位于生产者和队列中间，生产者并不关心将消息发送给哪个队列，而是将消息发送Exchage,由Exchange上配置的策略来决定将消息投递到哪个队列中。
![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq03.png)

同一份消息如果需要被多个消费者来消费，需要配置Exchange将消息发送到多个队列，每个队列中都存放一份完整的消息数据，可以为一个消费者提供消费服务。这也可以变相的实现“发布-订阅模型”中一份消息可以被多个订阅者来多次消费的功能。

### RocketMQ 的消息模型
Rocket使用的消息模型是标准的发布订阅模型。但是RocketMQ也有队列（Queue）这个概念，并且队列在RocketMQ中是一个非常重要的概念，那队列在RokcetMQ中的作用是什么呢？这就要从消息队列的消费机制说起。

几乎所有的消息队列产品都使用一种非常朴素的`“请求-确认”`机制，确保消息不会在传递过程中由于网络或者服务器故障丢失。具体的做法非常简单，在生产端，生产者现将消息发给服务端，也就是Broker，服务端在收到消息并将消息写入主题或队列中后，会给发送者发送确认的响应。

如果生产者没有收到服务端的确认或者收到失败的响应，则会重新发送消息；在消费端，消费者在收到消息并完成自己的消费业务逻辑（比如进行减库存操作）后，也会给服务端发送消费成功的确认，服务端只有收到消费确认后，才认为一条消息被成功消费，否则它会给消费者重新发送这条消息，直到收到对应的消费成功确认。

这个机制很好的确保了消息传递过程中的可靠性，但是，引入这个机制给消费端带来了一个不小的问题：为了确保消息的有序性，在某一条消息被成功消费之前，下一条消息是不能被消费的，否则会出现消息空洞，违背了有序性这个原则。

也就是说，每个主题在任意时刻，至多只有一个消费者实例在进行消费，那就无法通过水平拓展消费者的数量来提升消费端总体的性能，为了解决这个问题，RocketMQ在主题下面增加了队列的概念。

**每个主题包含多个队列，通过多个队列来实现多实例并行生产和消费。**需要注意的是，RocketMQ只在队列上保证消息的有序性，主题层面上无法保证消息的严格顺序。

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq04.png)

RocketMQ中，订阅者的概念是通过订阅组（Consumer Group）来体现的。每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响，也就是说，一条消息被Consumer Group1消费过，也会再给Consumer Group2消费。

消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者杜负责消费组内的一部分消息。如果一条消息被消费者Consumer1消费了，那同组的其他消费者就不会再收到这条消息。

在Topic的消费过程中，由于消息需要被不用的组进行多次消费，所以消费完的消息并不会被立即删除，这就需要RocketMQ为每一个消费组在每个队列上维护一个消费位置（Consumer Offset），这个位置之前是的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。这个消费位置是非常重要的概念，`在使用消费队列的时候，丢消息的原因大多数是应为消费位置处理不当导致的。`

### Kafka的消息模型
Kafka的消息模型与RockeMQ是一致的。唯一的区别就是队列这个名称在Kafka中称为“分区（Partition）”，含义和功能上是没有任何区别的。

## 四.利用消息队列实现分布式事务

在日常是使用事务的场景，无外乎就是在操作数据库的时候。像MySQL,Oracle 这些主流的关系型数据库，也都提供的完整的事务实现。那消息队列为什么也需要事务呢？

其实在很多场景下，我们发消息这个过程，目的往往就是通知另外一个系统或模块去更新数据，`消息队列中的事务，主要解决的就是消息生产者和消息消费者的数据一致性问题。`

就以电商项目为例。订单系统创建订单后，发消息给购物车系统，将已下单的商品从购物车中删除，因为从购物车中删除已下单的商品这个步骤，并不是用户下单支付这个主要流程中的必需的步骤，使用消息队列来异步清除购物车是更加合理的设计。
![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq05.png)

对于订单系统来说，创建订单的过程中实际上是执行了2个步骤的操作：
- 1.在订单库中插入一条订单数据，创建订单；
- 2.发消息给消息队列，消息的内容就是刚刚创建的订单。

购物车系统订阅相应的主题，接受订单创建的消息，然后清理购物车，在购物车中删除订单中的商品。

在分布式系统总，上面提到的这些步骤，任何一个步骤都有可能失败，如果不做任何处理，那么就可能出现订单数据和购物车数据不一致的情况，例如：
- 创建了订单并没有清理购物车；
- 订单没创建成功，购物车里面的商品却被清掉了。

需要解决的问题可以总结为：在上述任一步骤都有可能失败的情况下，还要保证订单库和购物车库这两个库的数据的一致性。

对于购物车系统收到订单创建成功消息清理购物车这个操作来说，失败的处理比较简单，只要成功执行购物车清理后再提交消费确认即可，如果失败，由于没有提交消费确认，消息队列就会自动重试。

问题的关键点集中在订单系统，创建订单和发送消息这两个步骤要么都操作成功，要么都操作失败，不允许一个成功一个失败的情况出现。

### 什么是分布式事务

如果我们需要对若干数据进行更新操作，为了保证这些数据的完整性和一致性，我们希望这些更新操作`要么都成功，要么都失败`。至于更新的数据，不只局限于数据库中的数据，也可能是磁盘上的一个文件，也可以是远端的一个服务，或者以其他形式存储的数据。

一个严格意义的事务实现，应该具有4个属性：`原子性`、`一致性`、`隔离性`和`持久性`。（ACID）
- 原子性：是指一个事务的操作不可分割，要么失败，要么成功，不能有一般成功一半失败的情况。
- 一致性:是指这些数据在事务执行完成这个时间点之前，读到的一定是更新前的数据，之后读到的一定是更新后的数据，不应该存在一个时刻，让用户读到更新过程中的数据。
- 隔离性：是指一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对正在进行的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。
- 持久性：是指一个事务一旦提交，后续的其他操作和故障都不会对事务的结果产生任何影响。

大部分传统的单体关系型数据库都完整的实现了ACID,但是，对于分布式系统来说，严格的实现ACID这四个特性几乎是不可能的，或者是实现的代价太大。

目前大家所说的分布式事务，更多情况下，是在分布式系统中事物的不完整实现。在不同的应用场景中，有不同的实现，目的是通过一些妥协来解决方案。

在实际的应用中，比较常见的分布式事务实现由 `2PC(Two-phase Commit，也叫做二阶段提交)`、`TCC(Try-Confirm-Cancel)`和`事务消息`。每一种实现都有其特定的使用场景，也有各自的问题，都不是完美的解决方案。

事务消息使用的场景主要是那些需要`异步更新数据`，并且对`数据实时性要求不太高的场景`。比如之前的例子，创建订单之后，如果出现短暂的几秒，购物车中的商品被没有及时清空，也不是完全不可以接受的，只是最终购物车的数据和订单数据保持一致就可以了。

### 消息队列是如何实现分布式事务的

事务消息需要消息队列提供相应的功能才能实现，Kafka和RocketMQ都提供了事务相关的功能。

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq06.png)

首先，订单系统在消息队列中开启一个事务，然后订单系统给消息服务器发送一个`“半消息”`，这个半消息并不是说消息是不完整的，它包含的内容就是完整的消息内容，半消息和普通消息的唯一区别是，在事务提交之前，对于消费者来说，这个消息是不可见的。

半消息发送成功之后，订单系统就可以执行本地事务了，在订单库中创建一条订单记录，并提交订单库的数据库事务。然后根据本地事务的执行结果提交或回滚事务消息。如果订单创建成功，那就提交事务消息，购物车系统就可以消费到这条消息然后继续后续的流程；如果订单创建失败，那就回滚事务消息，购物车系统就不会收到这条消息。n那么就基本实现了“要么都成功，要么都失败”的一致性要求。

但是，如果仅仅只是这样做还是有问题没有解决。如果在第四步提交事务消息失败了怎么办？kafka和RocketMQ给出了不同的解决方法。

Kafka的解决方案比较简单粗暴，直接抛出异常，让用户自行解决，我们可以在业务代码中重试提交，直到提交成功，或者也可以在删除之前创建的订单进行补偿。

**RocketMQ中分布式事务实现**

在RocketMQ中的事务实现中，增加了事务反查的机制来解决事务消息提交失败的问题。如果Producer 也就是订单系统，在提交或者回滚事务时发生了网络异常，RocketMQ的Broker没有收到提交或者回滚的请求，Broker会定期去Producer上反查这个事务对应的本地事务的状态，然后根据反查的结果决定提交或者回滚这个事务。


为了支撑这个事务反查机制，业务代码需要实现一个反查本地事务状态的接口，告知RabbitMQ本地事务是成功还是失败的。

在上面的例子中，我们只需要根据消息中的订单ID，在订单库中查询这个订单是否存在即可，如果订单存在则返回成功，否则返回失败。RocketMQ会自动根据实物反查的结果提交或者回滚事务消息。

这个反查本地事务的实现，并不依赖于消息的发送方，也就是订单服务的某个实例节点上的任何数据。这种情况下，即使是发送事务消息的那个订单服务节点宕机了，RocketMQ依旧可以通过其他订单服务的节点进行反查，确保事务的完整性。

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/07.png)

参考 https://rocketmq.apache.org/docs/transaction-example/

## 五.如何保证消息不丢失
现在主流的消息队列产品都提供了非常完善的消息可靠性机制，完全可以做到在消息传递的过程中，即使网络中断或者硬件故障，也能确保消息的可靠传输，不丢失消息。

绝大部分丢消息的原因都是由于开发者不熟悉消息队列，没有正确的使用和配置消息队列导致的。虽然不同的消息队列提供的API不一样，相关的配置项也不同，但是在保证消息可靠性传递这方面，它们实现原理是一样的。

### 检测消息丢失的方法

一个IT基础设施比较完善的公司，一般都有分布式链路系统，使用类似的追踪系统可以很方便地追踪每一条消息。

`我们可以利用消息队列的有序性来验证是否有消息丢失`。原理非常简单，在Producer端，我们每发出的消息附加一个递增的序号，然后在Consumer端来检查这个序号的连续性。

如果没有消息丢失，Consumer收到消息的序号必然是递增的，或者说收到的消息，其中的序号必然是上一条消息的序号+1，如果检测到的序号不连续，就是丢失消息了。还可以通过确实的序号来确定丢失的是哪一条消息，方便进一步排查原因。

大多数的消息队列客户端都支持拦截器机制，可以利用这个拦截器机制，在Producer发送消息之前的拦截器将序号注入到消息中，在Consumer收到消息的拦截器中检测序号的连续性，这样实现的好处就是消息的检测代码不会入侵到业务代码中，待系统稳定后，可以方便将这部分检测的逻辑关闭或者删除。

如果是一个分布式系统中实现这个检测方法，需要注意以下几个问题：

- 想Kafka 和 RocketMQ 这样的消息队列，它是不保证在Topic上的严格顺序的，只能保证分区上的消息是有序的，所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。

如果系统中的 Producer是多实例的，有序并不好协调多个Producer之前的发送顺序，所以也需要每个Producer分别生成各自的消息序列，并且需要附加上Producer的标识，在Consumer端按照每个Producer分别来检测序号的连续性。

Consumer 实例的数量最好和分区的数量一致，做到Consumer和分区一一对应，这样会比较方便得在Consumer内检测消息序号的连续性。

### 确保消息的可靠传输

一条消息从生产到消费完成这个过程，可以划分为三个阶段：

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq07png)

- 生产阶段：在这个阶段，从消息在Producer创建出来，经过网络传输发送给Broker端。
- 存储阶段：在这个阶段，消息在Broker端存储，如果是集群，消息会在这个阶段复制到其他副本上。
- 消费阶段：在这个阶段，Consumer从Broker上拉取消息，经过网络传输发送到Consumer上。

**1.1 生产阶段**

在生产阶段，消息队列通过最常用的请求确认机制，来保证消息的可靠传输：当你的代码调用发消息的方法时，消息队列的客户端会把消息发送给Broker,Broker收到消息后，会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，完成了一次正常消息的发送。

只要Producer收到了Broker的确认响应，就可以保证消息在生产阶段不会丢失。有些消息队列在长时间没有收到发送确认响应后，会自动重试，如果重试再失败，就会以返回值或者异常的方式告知用户。

在编写发送消息的代码时，`正确处理返回值或捕获异常，就可以保证这个阶段的消息不会丢失`。

以Kafaka为例，如何可靠地发送消息：

```java
try {
    RecordMetadata metadata = producer.send(record).get();
    System.out.println(" 消息发送成功。");
} catch (Throwable e) {
    System.out.println(" 消息发送失败！");
    System.out.println(e);
}
```

异步发送时，则需要在回调方法里进行检查，很多丢失消息的原因，就是因为使用了异步发送，却没有在回调方法中检查发送结果。
```java
producer.send(record, (metadata, exception) -> {
    if (metadata != null) {
        System.out.println(" 消息发送成功。");
    } else {
        System.out.println(" 消息发送失败！");
        System.out.println(exception);
    }
});
```

**1.2 存储阶段**

在存储阶段正常的情况下，只要Broker在正常的运行，消息就不会丢失，但是如果Broker出现了故障，比如进程死掉或者服务器宕机了，还是可能会丢失消息的。

如果对消息测可靠性要求非常高，可以通过`配置Broker参数`来避免因为宕机丢失消息。
对于单个节点的Broker，需要配置Broker参数，在收到消息后，将消息写入磁盘再给Producer返回确认响应，这样即使宕机，由于消息已经写入磁盘，就不会丢失消息，恢复后还可以继续消费。例如，在RocketMQ中，需要将刷盘方式`flushDiskType`配置为`SYNC_FLUSH`同步刷盘。

如果Broker是由多个节点组成的集群，需要Broker集群配置为：至少将消息两个以上的节点，再给客户端发送确认响应。这样在某个Broker宕机时，其他Broker可以替代宕机的Broker，也不会发生消息丢失。

**1.3 消费阶段**

消费阶段采用的是和生产阶段类似的消息确认机制确保消息的可靠传递，客户端从Broker拉取消息后，执行用户的消费业务逻辑，成功后，才会给Broker发送消费确认响应。如果Broker没收到消费确认响应，下次拉消息的时候还会返回同一条消息，确保消息不会在网络传输中丢失，也不会因为客户端在执行消费逻辑的时候出错而导致消息丢失。

在编写消费代码时需注意：`不要在收到消息后立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。`

以消费RabbitMQ为例，如何实现一段可靠的消费代码：
```python
def callback(ch, method, properties, body):
    print(" [x] 收到消息 %r" % body)
    # 在这儿处理收到的消息
    database.save(body)
    print(" [x] 消费完成 ")
    # 完成消费业务逻辑后发送消费确认响应
    ch.basic_ack(delivery_tag = method.delivery_tag)
 
channel.basic_consume(queue='hello', on_message_callback=callback)
```

>在消费的回到方法callback中，正确的顺序是，先把消息存储到数据库，然后再发送消费确认响应，这样保存消息到数据库失败，就不会执行消费确认的代码，下次拉到的还是这条消息，知道消费成功。

**总结**

- 生产阶段：需要捕获消息发送的错误，并重发消息。
- 存储阶段：通过配置刷盘和复制相关的参数，让消息写到多个副本的磁盘上，来确保消息不会因为某个Broker宕机或者磁盘损坏而丢失。
- 消费阶段:需要在处理完所有的消费逻辑之后，再发送消费确认的响应。

## 六.如何处理消费过程中的重复消息

在消息传递过程中，如果出现传递失败的情况，发送方就会执行重试，重试过程中就可能会产生重复的消息。对使用消息队列的业务系统来说，如果没有对重复消息进行处理，就有可能会导致系统的数据出现错误。

### 消息重复的情况必然存在

在MQTT协议中，给出了三种传递消息时能够提供的服务质量标准，这三种服务质量从低到高依次是：
- **At most once**:至多一次。消息在传递时，最多会被送达一次。换个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些消息可靠性要求不高的监控场景使用，比如每分钟上报一次机房的温度，可以接受少量消息的丢失。
- **At least once**:至少一次。消息在传递时，至少会被送达。也就是说，不允许丢失消息，但是允许少量的重复消息。
- **Exactly once**:恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高等级。

>MQTT（消息队列遥测传输）是ISO标准（ISO/IEC PRF 20922）下基于发布/订阅范式的消息协议。它工作在TCP/IP协议族上，是为硬件性能低下的远程设备以及网络状况糟糕的情况下而设计的发布/订阅型消息协议，为此，它需要一个消息中间件 。

这个服务质量标准不仅适用于MQTT，对所有的消息队列都是适用的。我们现在常用的绝大部分消息队列提供的服务质量都是At least once,包括RabbitMQ,RocketMQ和kafka都是这样。也就是说消息队列很难保证消息不重复。

需要注意的是，Kafaka文档中表示Kafka是支持Exactly once的。但是，它和服务质量标准的Exactly once是不一样的，它是Kafka另外一个特性，Kafka中支持的事务也和我们通常意义上的事务有一定的差异。`在Kafka中支持的事务和Exactly once 主要是为了配合流计算使用的特性。`

### 用幂等性解决重复消息问题

>一般解决重复消息的办法是，在消费端，让我们消费消息的操作具备幂等性。

**对系统的影响：At least once + 幂等消费 = Exactly once**

实现幂等操作最好的方式就是：`从业务逻辑设计上入手，将消费的业务逻辑设计成具备幂等性的操作。`

集中常见的设计幂等操作的方法：

**1.利用数据库的唯一约束实现幂等**

举一个例子，每次转账100元，要实现对于每个转账单个账户只可以执行一次变更操作，在分布式系统中，这个限制实现的方法非常多，最简单的就是可以在数据库中新建一张转账流水表，这个表中有三个字段:转账单ID、账户ID以及变更金额，然后用`转账单ID和账户ID这两个字段联合起来创建一个唯一约束`，这样对于相同的转账单ID和账户ID,表里至多有一条数据。

这样我们的消费逻辑就可以变为：“在转账流水表中增加一条转账记录，然后再根据转账记录，异步操作更新用户余额。” 在转账流水表中增加一条转账记录这个操作中，由于我们在这个表中预先定义了“账户ID转账单ID”的唯一约束，对于同一个转账单同一个账户只能插入一条记录，后续重复的插入操作都会失败，这样就实现了一个幂等操作。我们只需要写一个SQL，正确的实现它就可以了。

基于这个思路，不光是可以使用关系型数据库，只要是支持类似“**INSERT IF NOT EXIST**”语义的存储系统都可以实现幂等。比如，`可以用 Redis 的 SETNX 命令来替代数据库中的唯一约束`，来实现消息幂等。

**2.为更新数据设置前置条件**

给数据变更设置一个前置条件，如果满足条件就更新数据，否则就拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。这样，重复执行这个数据时，由于第一次更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据库。

如果我们要更新的数据不是数值，或者要进行一个比较复杂的更新操作时，更加通用的方法是给你的数据增加一个版本号属性，每次更新数据前，比较当前数据的版本号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据之后可以把版本号+1，一样可以实现幂等更新。

**3.记录并检查操作**

还有一种通用性最强，适用范围最广的幂等性实现方法：记录并检查操作，也称为“Token机制或者GUID(全局唯一ID)机制”，实现的思路非常简单：`在执行数据更新操作之前，先检查一下是否执行过这个更新操作。`

具体的实现方法是，在发送消息是，给每条消息指定一个全局唯一的ID，消费时，先根据这个ID检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后把消费状态置为已消费。

在分布式系统中，这种方法其实是很难实现的。首先，给每一条消息指定一个全局唯一的ID就不是一件简单的事，方法有很多，但都不太好同时满足简单、高可用和高性能。更加麻烦的是，在“检查消费状态，然后更新数据并且设置消费状态”中，三个操作必须作为一组操作保证原子性，才能真正实现幂等。

比如说，对于同一条消息：“全局ID为8，操作为：给ID为666账户增加了100元”，有可能出现这样的情况：

- t0时刻：ConsumerA收到消息，检查消息执行状态，发现消息并未处理，开始执行“账户增加100元”；
- t1时刻：ConsumerB收到消息，检查消息执行状态，发现消息未处理过，因为这个时刻ConsumerA还未来得及更新消息执行状态。

这样就会导致账户被错误地增加两次100元，这是一个分布式系统中非常容易犯的错误。

对于这个问题，我们可以用事务来实现，也可以用锁来实现。

**思考**：为什么大部分的消息队列都选择只提供At least once 的质量，而不是级别更高的Exactly once 呢？

若消息队列实现了exactly once，会引发的问题可能有：

①消费端在pull消息时，需要检测此消息是否被消费，这个检测机制无疑会拉低消息消费的速度。可以预想到，随着消息的剧增，消费性能势必会急剧下降，导致消息积压；

②检查机制还需要业务端去配合实现，若一条消息长时间未返回ack，消息队列需要去回调看下消费结果（这个类似于事物消息的回查机制）。这样就会增加业务端的压力，与很多的未知因素。

## 七.消息积压了怎么处理

在消息队列的使用过程中，最常遇到的问题，就是消息积压的问题。消息积压的原因，一定是系统中某一个部分出现了性能问题，来不及处理上游发送的消息，才会导致消息积压。

### 1.优化性能来避免消息积压

在使用消息队列的系统中，对于性能的优化，主要体现在生产者和消费者这一收一发来个部分的业务逻辑中。对于消息队列本身的性能，作为使用者，不需要太关注，因为绝大多数使用消息队列的业务业务来说，消息队列本身的处理能力要远大于业务系统的处理能力。主流消息队列的单个节点，消息收发的性能可以达到每秒中处理几万至几十万条消息的水平，还可以`通过水平拓展Broker的实例数成倍地提升处理能力`。

而一般的业务系统需要处理的业务逻辑远比消息队列复杂，单个节点每秒可以处理几百到几千次的请求，已经可以算是性能非常好了。所以，对于消息队列的性能优化，我们更要关注的是，在消息收发两端，我们的业务代码怎么和消息队列相配合，达到一个最佳的性能。

**1.发送端性能优化**

发送端业务代码的处理性能，实际上和消息队列的关系不大，因为一般发送端都是先执行自己的业务逻辑，最后再发送消息。如果说，**你的代码发送消息的性能上不去，你需要优先检查一下，是不是发消息之前的业务逻辑耗时太多导致的**。

对于发送消息的业务逻辑，只需要注意**设置合适的并发和批量大小**，就可以达到很好的发送性能。

Producer 发送消息的过程，Producer发消息给Broker，Broker收到消息后返回确认响应，这是一次完整的交互。假设这一次的交互平均延时为1ms,把这 1ms 的时间分解开，它包括了下面这些步骤的耗时：

- 1.发送端准备数据、序列化消息、构造请求等逻辑的时间，也就是发送端在发送网络请求之前的耗时；
- 2.发送消息和返回响应在网络传输中的耗时；
- 3.Broker 处理消息的耗时

如果是单线程发送，每次只发送一条消息，那么每秒只能发送1000ms/1ms*1条/ms = 1000 条消息，这种情况下并不能发挥出消息队列的全部实力。

无论是增加每次发送消息的批量大小，还是增加并发，都能够成倍地提升性能。至于到底是选择批量发送还是增加并发，主要取决于发送端程序的业务性质。简单来说，这要能够满足性能要求，怎么实现方便就实现。

比如说，你的消息发送端是一个微服务，主要接收的是RPC请求处理的在线业务。很自然的，微服务在处理每次请求的时候，就在当前线程直接发送消息就可以了，因为所有RPC框架都是多线程支持多并发的，自然也就实现了并行发送消息。并且在线业务比较在意的是请求响应时延，选择批量发送必然会影响RPC服务的延时，这种情况，比较明智的方式就是通过并发来提升性能。

如果你的系统是一个离线分析系统，不关心时延，更加注重整个系统的吞吐量。发送端的数据都来自数据库，这种情况更适合批量发送，可以批量从数据库读取数据，然后批量发送数据，这样可以用少量的并发就可以获取非常高的吞吐量。

**2.消费端性能优化**

使用消息队列的时候，大部分的性能问题都出现在消费端，如果消费端消费的速度跟不上发送端生产消息的速度，就会造成消息的积压，如果这种性能倒挂的问题只是暂时的，那问题不大，只要消费端的性能恢复之后，超过发送端的性能，那积压的消息就可以逐渐被消化掉。

要是消费速度一直比生产速度慢，时间长了之后，整个系统就会出现问题，要么消息队列的存储被填满无法提供服务，要么消息丢失，对于整个系统来说就是严重故障。

所以，我们在设计系统的时候，一定要保证**消费端的消费性能能要高于生产端的发送性能**，这样的系统才能健康的持续运行。

消费端的性能优化除了优化消费业务逻辑以外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能。特别要注意的一点就是，在扩容Consumer的实例数量的同時，必須同步扩容主题中的分区（也叫队列）数量，确保Consumer的实例数和分区数量是相等的。如果Consumer 的实例数量超过分区数量，这样的扩容实际上是么有效果的，因为**对于消费者来说，在每个分区上实际上只支持单线程消费**。

常见的`错误的`解决消费慢的解决方案：


















