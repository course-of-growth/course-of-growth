## 一.消息队列解决了哪些问题
通俗来说，消息队列的主要功能就是收发消息，但是它的作用不仅仅只是解决应用之间的通信问题这么简单。

日常开发中哪些问题适合使用消息队列来解决呢？

### 1.异步处理

就以前段时间面试最火的问题————如何设计一个秒杀系统举例。`秒杀系统需要解决的核心问题就是如何利用好有限的服务器资源，尽可能多地处理短时间内的海量的数据请求`。

一般秒杀请求包含以下几个步骤：
- 风险控制
- 库存锁定
- 生成订单
- 短信通知
- 更新统计数据

如果没有任何的优化的话，正常的处理流程就是：APP将请求发送给网关了，依次调用以上5个流程，然后将结果返回给APP.
对于这五个步骤来说，能否决定秒杀成功，实际上只有风险控制和库存锁定这两个步骤。只要用户的秒杀请求完成这两个步骤，对于后续的步骤，并不一定要在秒杀请求中处理完成，而是可以`将请求的数据放入消息队列中，有消息队列异步地进行后续的操作`，可以充分利用有限的服务资源处理更多真正的秒杀请求。

![Image text](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/miaosha.png)


优点：
- 更快地返回结果
- 减少等待，自然实现了步骤之间的并发，提升了系统总体的性能

>网关接受后端服务秒杀结果，实现的方式不止一种，下面提供一个比较简单的方式：

```java
public class RequestHandler {
  
  // ID 生成器
  @Inject
  private IdGenerator idGenerator;
  // 消息队列生产者
  @Inject
  private Producer producer;
  // 保存秒杀结果的 Map
  @Inject
  private Map<Long, Result> results;
 
  // 保存 mutex 的 Map
  private Map<Long, Object> mutexes = new ConcurrentHashMap<>();
  // 这个网关实例的 ID
  @Inject
  private long myId;
 
  @Inject
  private long timeout;
 
  // 在这里处理 APP 的秒杀请求
  public Response onRequest(Request request) {
    // 获取一个进程内唯一的 UUID 作为请求 id
    Long uuid = idGenerator.next();
    try {
 
      Message msg = composeMsg(request, uuid, myId);
 
      // 生成一个 mutex，用于等待和通知
      Object mutex = new Object();
      mutexes.put(uuid, mutex)
 
      // 发消息
      producer.send(msg);
 
      // 等待后端处理
      synchronized(mutex) {
        mutex.wait(timeout);
      }
 
      // 查询秒杀结果
      Result result = results.remove(uuid);
 
      // 检查秒杀结果并返回响应
      if(null != result && result.success()){
        return Response.success();
      }
 
    } catch (Throwable ignored) {}
    finally {
      mutexes.remove(uuid);
    }
    // 返回秒杀失败
    return Response.fail();
  }
 
  // 在这里处理后端服务返回的秒杀结果
  public void onResult(Result result) {
 
    Object mutex = mutexes.get(result.uuid());
    if(null != mutex) { // 如果查询不到，说明已经超时了，丢弃 result 即可。
      // 登记秒杀结果
      results.put(result.uuid(), result);
      // 唤醒处理 APP 请求的线程
      synchronized(mutex) {
        mutex.notify();
      }
    }
  }
}
```

在这种方案中，网关在收到 APP 的秒杀请求后， 直接给消息队列发消息。至于消息的内容，不一定是APP 请求的Request，只要包含足够的字段就行了，比如用户ID、设备ID、请求时间等等。另外，还需要包含这个请求的ID 和网关的ID，这些后面都会用到。

如果发送消息失败，可以直接给APP 返回秒杀失败结果，成功发送消息之后，线程就会阻塞等待秒杀结果。这里面不可能无限等待下去，需要设定一个等待的超时时间。

等待结束之后，去存放秒杀结果的Map中查询是否有返回秒杀结果，如果有就构建Response,给App返回秒杀结果，如果没有，按秒杀失败处理。

这是处理 APP 请求的线程，接下来我们看一下，网关如何接受从后端秒杀服务返回的秒杀结果。

我们可以选择用RPC的方式来返回秒杀结果，这里的网关节点是RPC服务端，后端服务为客户端，之前网关发出去的消息中包含了网关的ID，后端服务可以通过这个网关ID 来找对应的网关实例，秒杀结果中需要包含请求ID，这个请求ID也是从消息中获取的。

网关收到后端服务的秒杀结果之后，用请求ID为key，把这个结果保存到秒杀结果的Map中，然后通知对应的处理APP 请求的线程，结束等待。处理 APP 请求的线程，在结束等待之后，会去秒杀的结果Map中查询这个结果，然后再给APP 返回响应。

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq12.jpg)

这个解决方案还不是一个性能最优的方案，处理APP请求的线程需要同步等待秒杀结果。可以使用异步方式提高程序的性能。


### 2.流量控制
一个设计健壮的程序有自我保护能力，也就是说，它能够在海量的请求下，还能在自身能力范围内尽可能多地处理请求，拒绝处理不了请求并且保证自身正常运行。但是大多的程序并没有那么“健壮”，而直接拒绝请求返回错误对于用户来说体验也不好。

因此，需要设计一套健壮的架构来将后端的服务保护起来。一般的设计思路是： `使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的`。

加入消息队列后，整个秒杀流程变为：
- 1.网关在收到请求后，将请求放入消息队列中
- 2.后端服务从请求消息队列中获取APP请求，完成后续秒杀处理过程，然后返回结果。
![Image text](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq1.png)

秒杀开始后，当短时间内的大量秒杀请求到达网关后，不会直接冲击到后端的秒杀服务，而是先堆积在消息队列中，后端服务按照自己的最大处理能力，从消息队列中消费请求进行处理。

对于`超时`的请求可以直接丢弃，APP将超时无响应的请求处理为秒杀失败即可。运维人员还可以随时增加秒杀服务的实例数量进行水平扩容，而不用对系统的其他部分做任何的修改。

这样设计的优点就是：`能根据下游的处理能力自行调节流量，达到“削峰填谷”的作用`。

但是同样这种设计也有缺点：
- 增加了系统的调用链，导致总体的响应时间变长
- 上下游系统都要将同步调用调整为异步消息，增加了系统的复杂度。


除了上面的那种方式以外，还有相对简单的流量控制方法：如果可以预估出秒杀服务的处理能力，就可以用消息队列实现一个令牌桶，更加简单地进行流量控制。

令牌桶控制流量的原理就是：单位时间内只发放固定数量的令牌到令牌桶中，规定服务在处理请求之前必须从令牌桶中拿出一个令牌，如果令牌桶中没有令牌，则拒绝请求。这样就可以保证单位时间内请求的数量不会超过发放令牌的数量，起到了流量控制的作用。

![Image text](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq2.png)

其实现方式也很简单，不需要破坏原有的调用链，只要网关在处理APP请求时增加一个获取令牌的逻辑

令牌桶可以简单地用一个有固有容量的消息队列加一个“令牌发生器”来实现；令牌发生器按照预估的处理能力，均速生成令牌并放入令牌队列（如果队列满了则丢弃令牌），网关在收到请求时去令牌对列消费一个令牌。获取到令牌，获取到立牌则继续调用后端秒杀服务，如果获取不到令牌则直接返回秒杀失败。

### 3.服务解耦
消息队列还可以实现系统应用之间的解耦。

就以常见的电商项目为例，订单系统是比较核心的系统，当一个新的订单创建的时候
- 1.支付系统需要发起支付流程
- 2.风控系统需要审核订单的合法性
- 3.客服系统需要短息通知用户
- 4.运营分析系统需要更新数据
...

这些订单下游的系统都需要实时获得订单数据。随着业务不断发展，这些订单下游系统不断的增加，不断变化，并且每个系统可能只需要订单数据的一个子集，负责订单服务的开发团队不得不花费很大的精力，应对不断增加变化的下游系统，不停地修改调试订单系统与这些下游系统的接口。任何一个下游系统接口变更，都需要订单模块重新进行一次上线，对于一个电商的核心服务来说，这几乎是不可接受的。

所有的电商都选择用消息队列来解决类似的系统耦合过于紧密的问题。引入消息队列后，订单服务在订单变化时发送一条消息到消息队列的一个主题 Order 中，所有下游系统都订阅主题 Order，这样每个下游系统都可以获得一份实时完整的订单数据。

无论增加、减少下游系统或是下游系统需求如何变化，订单服务都无需做任何更改，实现了订单服务与下游服务的解耦。

### 其他
除了上面的三种最为常见的使用场景，还包括：
- 作为发布/订阅系统实现一个微服务级系统间的观察者模式；
- 连接流计算任务和数据
- 用于将消息广播给大量的接受者

简单的来说，我们在单体应用里面需要用到消息队列解决的问题，在分布式系统中大多数都可以用消息队列来解决

消息队列也有其自身的一些问题和局限性：
- 引入消息队列带来的延迟问题
- 增加了系统的复杂度
- 可能会出现数据一致性问题

参考：
```
Understanding When to use RabbitMQ or Apache Kafka ，什么时候使用 RabbitMQ，什么时候使用 Kafka，通过这篇文章可以让你明白如何做技术决策。
Trello: Why We Chose Kafka For The Trello Socket Architecture ，Trello 的 Kafka 架构分享。
LinkedIn: Running Kafka At Scale ，LinkedIn 公司的 Kafka 架构扩展实践。
Should You Put Several Event Types in the Same Kafka Topic? ，这个问题可能经常困扰你，这篇文章可以为你找到答案。
Billions of Messages a Day - Yelp’s Real-time Data Pipeline ，Yelp 公司每天十亿级实时消息的架构。
Uber: Building Reliable Reprocessing and Dead Letter Queues with Kafka ，Uber 公司的 Kafka 应用。
Uber: Introducing Chaperone: How Uber Engineering Audits Kafka End-to-End ，Uber 公司对 Kafka 消息的端到端审计。
Publishing with Apache Kafka at The New York Times ，纽约时报的 Kafka 工程实践。
Kafka Streams on Heroku ，Heroku 公司的 Kafka Streams 实践。
Salesforce: How Apache Kafka Inspired Our Platform Events Architecture ，Salesforce 的 Kafka 工程实践。
Exactly-once Semantics are Possible: Here’s How Kafka Does it ，怎样用 Kafka 让只发送一次的语义变为可能。这是业界中一个很难的工程问题。
Delivering billions of messages exactly once 同上，这也是一篇挑战消息只发送一次这个技术难题的文章。
Benchmarking Streaming Computation Engines at Yahoo!。Yahoo! 的 Storm 团队在为他们的流式计算做技术选型时，发现市面上缺乏针对不同计算平台的性能基准测试。于是，他们研究并设计了一种方案来做基准测试，测试了 Apache Flink、Apache Storm 和 Apache Spark 这三种平台。文中给出了结论和具体的测试方案。（如果原文链接不可用，请尝试搜索引擎对该网页的快照。） 
```

## 二.如何选择消息队列
常见的消息队列中间件有很多，每一种产品都有自己的优缺点，所以就需要根据现有系统的情况，选择最合适的产品。
一个合格的消息队列中间件，必须具备一下几个特性：
- 消息可靠传递：确保不丢失消息；
- Cluster:支持集群，确保不会因为某个节点宕机导致服务不可用，本质上也是要保证消息不丢失；
- 性能：具备良好的性能，能够满足绝大多数场景下的性能要求。

### 常见的几种消息队列
- `RabbitMQ`

Erlang语言编写，是少数几个支持AMQP协议的消息队列之一。

Rabbit的宣传口号是：Messaging that just works ,"开箱即用的消息队列"。也就是说，`RabbitMQ是一个相当轻量级的消息队列，非常容易部署及使用`。

RabbitMQ 还有一个比较有特色的的功能就是支持非常灵活的路由配置，和其他消息队列不同的是，它在生产者（Producer）和队列（Queue）之间增加了一个Exchange模块，可以将其理解为交换机。

Exchange模块的作用和交换机也非常相似，根据配置的路由规则将生产者发出的消息分到不同的队列中。路由的规则也非常灵活，甚至可以自定义路由规则。

RabbitMQ客户端支持的编程语言大概是所有消息队列中最多的。

缺点：

**RabbitMQ对消息堆积的支持并不好，在它的设计理念中，消息队列是一个管道，大量的消息堆积是一种不正常的情况， 应当尽量的去避免。当大量的消息堆积时，会导致RabbitMQ的性能急剧下降。**

**RabbitMQ的性能相较于其他消息队列是最差的，大概每秒可以处理几万到几十万条消息，其实这个性能已经足够支撑绝大多数的应用场景了，但是，如果应用对消息队列的性能要求非常高的话，那就不要选择RabbitMQ。**

**RabbitMQ使用Erlang语言编写的，该语言难度较大，所以基于其做一些拓展或者二次开发，得慎重考虑维护问题。**


- `RocketMQ`

RocketMQ是阿里开源的消息队列产品，之后建赠与Apache软件基金会，有着不错的性能，稳定性和可靠性，具备一个现代消息队列应该有的几乎所有的功能和特性，并且他还在持续的成长中。

RocketMQ有非常活跃的中文社区，大多数的问题可以直接找到中文答案。此外，RocketMQ使用Java语言开发的，可以更容易对其进行二次开发或拓展。

RocketMQ对在线业务的响应延时做了很多的优化，大多数情况下都可以做到毫秒级的响应。如果应用场景很`在意响应延时`的话，就应该选择RocketMQ。

RocketMQ的性能比RabbitMQ要高出一个数量级，每秒钟大概可以处理几十万条消息。

RocketMQ的一个劣势就是作为国产的消息队列，相比于国外比较流行的同类产品，在国际上没那么流行，与周边生态系统的集成和兼容程度就要略逊一些了。

- `Kafka`

Kafka最早是由Linkedln开发，目前也是Apache的顶级项目，其最初设计目的在于处理海量的日志。

在早期Kafka为了获得极致的性能，在设计方面做出了很大的牺牲，比如不能保证消息的可靠性，可能会丢失消息，也不支持集群，功能上也比较简陋，这些牺牲对于处理海量日志这个特定的应用场景还是可以接受的。这个时期的Kafka甚至不能称为一个合格的消息队列。

但是，随着这几年Kafka的发展，当下Kafka已经是一个非常成熟的消息队列产品，无论在数据可靠性、稳定性和功能特性方面都可以满足绝大多数的场景需求。

kafka与周边生态系统的兼容性是最好的没有之一，尤其是在大数据和流计算领域，几乎所有的开源软件系统都会优先支持Kafka.

Kafka使用Scala和Java语言开发，设计上使用了批量和异步的思想，这种设计使得Kafka能够做到超高的性能。Kafka的性能，尤其是异步收发的性能，是三者中最好的，但是与RocketMQ并没有量级上的差异，大于每秒钟处理几十万条消息。

但是Kafka这种异步批量设计带来的问题可就是其`同步收发消息的响应延时较高`，因为当客户端发送一条消息的时候，Kafka并不会立即发送出去，而是`要等一会儿攒一批再发送`。所以当业务场景中每秒消息数量没有那么多时，Kafaka的时延反而会比较高。所以Kafka不太适合在线业务场景。

### 其他消息队列
ActiveMQ,老牌消息队列，与现代消息队列存在明显的差距,目前存在的意义就是兼容一些古老的系统。

ZeroMQ,严格来说它是一个基于消息队列的多线程网络库，如果需要消息队列的功能集成到系统进程中，可以考虑使用ZeroMQ。

Pulsar,新兴的开源消息队列产品，最早由Yahoo开发，目前处于成长期，流行度和成熟度相对没有那么高。与其他消息队列不同的是，Pulsar采用存储和计算分离的设计。

### 消息队列使用场景总结

系统对消息队列的功能和性能没有很高的要求，只需要一个开箱即用易于维护的产品，可以使用RabbitMQ。

系统使用消息队列的场景主要是处理在线业务，比如交易系统中用消息队列传递订单，可以使用RocketMQ，因为其低延迟和金融级的稳定性。

系统需要处理海量的消息，比如手机日志、监控信息或者前端的埋点这类数据，或是应用场景大量使用了大数据、流计算相关的开源产品，kafka是最适合的消息队列。 	 	 	 
 	 	 	 	 	 
参考地址  ：https://blog.csdn.net/belvine/article/details/80842240   

 

## 三.消息模型
每一款消息队列都有自己的一套消息模型，比如说队列（Queue）、主题（Topic）或者是分区（Partition）这些名词概念，在每个消息队列模型中都会涉及一些，含义还不太一样。

### 主题和队列有什么区别
最初的消息队列，就是一个严格意义上的队列。
> *队列是先进先出（FIFO, First-In-First-Out）的线性表（Linear List）。在具体应用中通常用链表或者数组来实现。队列只允许在后端（称为 rear）进行插入操作，在前端（称为 front）进行删除操作。*

在这个定义里面包含几个关键点，首先是先进先出，消息入队列的时候需要保证这些消息的严格有序，按照什么顺序进队列，必须按照同样的顺序从队列中读出来。但是队列是没有“读”这个操作的，“读”就是出队，也就是从队列中删除这条消息。

早期的消息队列近就是按照队列的数据结构设计的。生产者(Producer)发消息就是入队消息，消费者（Consumer）收消息就是出队也就是删除操作，服务端存放消息的容器自然就称为“队列”。

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq-model1.png)

如果有多个生产者往同一个队列中发送消息，这队列中可以消费到的消息，就是这些生产者的所有消息的合集。消息的顺序就是这些生产者发送消息的自然顺序。如果有多个消费者同时接受同一队列的消息，这些消费者之间实际上是竞争的关系，每个消费者只能收到队列中的一部分消息，也就是说任何一条消息只能被其中的一个消费者收到。

如果需要将一份消息数据分发给多个消费者，要求每个消费者都能收到全量的消息，例如，对于一份订单数据，风控系统、分析系统、支付系统等都需要就收消息。此时，单个队列就满足不了需求，一个可行的解决方法就是为每个消费者创建一个单独的队列，让生产者发送多份数。

但是这种方法显然是不合适的，同样一份消息数据被复制到多个队列中会浪费，更重要的是，生产这必须知道有多少个消费者。为每个消费者单独发送一份消息，这实际上违背了消息队列“解耦”这个设计初衷。

为了解决这一问题，演化了另外一种消息模型：“发布-订阅模型（Publish-Subscribe Pattern）”

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq-model02.png)

在发布-订阅模型中，消息的发送方称为发布者（Publisher），消息的接收方称为订阅者（Subsrciber），服务端存放消息的容器称为`主题（Topic）`，发布者将消息发送到主题中，订阅者在接受消息之前需要先“订阅主题”。“订阅”既是一个动作，同时还可以认为是主题在消费时的一个逻辑副本，每份订阅中，订阅者都可以接收到主题的所有消息。

在消息领域的历史上很长一段时间，队列模式和发布-订阅模式是并存的，有些消息队列同时支持这两种消息模型，比如ActiveMQ。仔细对比一下这两种模型，生产者就是发布者，消费者就是订阅者，队列就是主题，并没有本质的区别。它们最大的区别就是一份消息能不能被消费多次的问题。

实际上，在这种发布-订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。也就是说，发布-订阅模型在功能层面上是可以兼容队列模型的。

>现代的消息队列产品使用的消息模型大多数是发布-订阅模型，当然也有一些例外，比如RabbitMQ。

### RabbitMQ 的消息模型

RabbitMQ是少数依然坚持使用队列模型的产品之一。RabbitMQ的Exchange模块位于生产者和队列中间，生产者并不关心将消息发送给哪个队列，而是将消息发送Exchage,由Exchange上配置的策略来决定将消息投递到哪个队列中。
![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq03.png)

同一份消息如果需要被多个消费者来消费，需要配置Exchange将消息发送到多个队列，每个队列中都存放一份完整的消息数据，可以为一个消费者提供消费服务。这也可以变相的实现“发布-订阅模型”中一份消息可以被多个订阅者来多次消费的功能。

### RocketMQ 的消息模型

`RocketMQ`使用的消息模型是标准的`发布订阅`模型。但是RocketMQ也有队列（Queue）这个概念，并且队列在RocketMQ中是一个非常重要的概念，那队列在RokcetMQ中的作用是什么呢？这就要从消息队列的消费机制说起。

几乎所有的消息队列产品都使用一种非常朴素的`“请求-确认”`机制，确保消息不会在传递过程中由于网络或者服务器故障丢失。具体的做法非常简单，在生产端，生产者现将消息发给服务端，也就是Broker，服务端在收到消息并将消息写入主题或队列中后，会给发送者发送确认的响应。

如果生产者没有收到服务端的确认或者收到失败的响应，则会重新发送消息；在消费端，消费者在收到消息并完成自己的消费业务逻辑（比如进行减库存操作）后，也会给服务端发送消费成功的确认，服务端只有收到消费确认后，才认为一条消息被成功消费，否则它会给消费者重新发送这条消息，直到收到对应的消费成功确认。

这个机制很好的确保了消息传递过程中的可靠性，但是，引入这个机制给消费端带来了一个不小的问题：为了确保消息的有序性，在某一条消息被成功消费之前，下一条消息是不能被消费的，否则会出现消息空洞，违背了有序性这个原则。

也就是说，每个主题在任意时刻，至多只有一个消费者实例在进行消费，那就无法通过水平拓展消费者的数量来提升消费端总体的性能，为了解决这个问题，RocketMQ在主题下面增加了队列的概念。

**每个主题包含多个队列，通过多个队列来实现多实例并行生产和消费。**`需要注意的是，RocketMQ只在队列上保证消息的有序性，主题层面上无法保证消息的严格顺序。`

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq04.png)

RocketMQ中，订阅者的概念是通过订阅组（Consumer Group）来体现的。每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响，也就是说，一条消息被Consumer Group1消费过，也会再给Consumer Group2消费。

消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者负责消费组内的一部分消息。如果一条消息被消费者Consumer1消费了，那同组的其他消费者就不会再收到这条消息。

在Topic的消费过程中，由于消息需要被不用的组进行多次消费，所以消费完的消息并不会被立即删除，这就需要RocketMQ为每一个消费组在每个队列上维护一个**消费位置**（Consumer Offset），这个位置之前是的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。这个消费位置是非常重要的概念，`在使用消费队列的时候，丢消息的原因大多数是应为消费位置处理不当导致的。`

>假设一个 MyTopic,我们为主题创建5个队列，分布到2个 Broker 中。

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq13.jpg)

- 先说生产者这一端，假设我们有3个生产者实例:Producer0、Producer1、Producer2

这3个生产者是如何应对到2个 Broker 的，又是如何应对到5个队列的呢？这个很简单，`不用对应，随便发`。每个生产者可以在5个队列中轮询发送，也可以随机选一个队列发送，或者只往某个队列发送，这些都可以。比如Procuder0要发5条消息，可以都发到队列Q0里面，也可以5个队列每个队列都发一条。

- 然后说消费端，很多人没有搞懂消费组、消费者和队列这几个概念的对应关系。

`每个消费组就是一份订阅`，它要消费主体MyTopic下所有队列的全部消息。**注意，队列里的消息并不是消费掉就没有了，这里的“消费”，只是去队列中读了消息，并没有删除，消费完这条消息还是在队列里面。**

多个消费组在消费同一个主题时，消费组之间是互不影响的。比如我们有两个消费组：G0 和 G1。G0消费了哪些消息，G1是不知道的，也不用知道。G0 消费过的消息，G1还可以消费。即使G0积压了很多消息，对G1 来说是没有任何影响的。

在消费组内部，一个消费组中可以包含多个消费者实例。比如消费组G1，包含了2个消费者C0和C1,那这2个消费者又是怎么和主题MyTopic的5个队列对应的呢？

由于消费确认的机制，这里面有一个原则就是：`在同一个消费组里面，每个队列只能被一个消费者实例占用`。至于如何分配，这里面有很多策略。总之保证每个队列分配一个消费者就行了。比如，我们可以让消费者C0 消费 Q0,Q1和Q2，C1 消费Q3和Q4，如果C0 宕机了，会触发重新分配，这时候C1 同时消费全部5个队列。

最后在强调一下消费位置，每个消费组内部维护自己的一组消费位置，每个队列对应一个消费位置。消费位置在服务端保存，并且，`消费位置和消费者是没有关系的`。每个消费位置一般就是一个整数，记录这个消费组中，这个队列消费到哪个位置了，这个位置之前的消息都成功消费了，之后的消息都没有消费或者正在消费。

举例整理消费位置：

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq13.jpg)
>可以看出，这个表格并没有消费者这一列，也就是说消费者和消费位置是没有关系的。


### Kafka的消息模型
Kafka的消息模型与RockeMQ是一致的。唯一的区别就是队列这个名称在Kafka中称为“分区（Partition）”，含义和功能上是没有任何区别的。

### 如何实现单个队列的并行消费？

如果不要求严格顺序，如何实现单个队列的并行消费。对于这个问题，有很多的实现方式，在JMQ（京东自研的消息队列产品）中，它的实现思路是这样的：

*比如说，队列中当前有10条消息，对应的编号是0-9，当前的消费位置是5。同时来了3个消费者来拉取消息，把编号5.6.7的消息分别给了三个消费者，每人一条，过了一段时间，三个消费成功的响应都回来了，这时候就可以把消费位置更新为8了，这样就可以实现并行消费。*

这是比较理想的情况，还有可能是编号为6、7的消息响应回来了，但是编号5的消息响应一直回不来，怎么办，这个位置5就是一个`消息空洞`。为了避免位置5把这个队列卡主，可以先把消费位置5这条消息，复制到一个特殊重试队列中，然后依次把消费位置更新为8，继续消费。再有消费者来拉取消息的时候，优先把重试队列中的那条消息给消费者就可以了。

这是并行消费的一种实现方式，需要注意的是，并行消费开销是很大的，不应该作为一个常规的，提升消费并发的手段，如果消费慢需要增加消费者的并发数，还是需要扩容队列数。

### 如何保证消费的严格顺序

`主题层面是无法保证严格顺序的，只有在队列上才能保证消息的严格顺序。`

如果说，你的业务必须要求全局严格顺序，就只能把消息队列数配置成1，生产者和消费者也只能是一个实例，这样才能保证全局严格执行。

大部分的情况下，我们并不需要全局严格顺序，只要保证局部有序就可以了。比如，在传递账户流水记录的时候，只要保证每个账户的流水有序就可以了，不同账户之间的流水记录是不需要保证顺序的。

如果需要保证局部严格有序，可以这样来实现。在发送端，我们使用账户ID作为key,采用一致性哈徐算法计算出队列编号，指定队列来发送消息。`一致性哈希算法可以保证，相同key的消息总是发送到统一队列上，这样就可以保证相同key的消息是严格有序的，`如果不考虑队列扩容，也可以用队列数量取模的简单方法来计算队列编号。

## 四.利用消息队列实现分布式事务

在日常是使用事务的场景，无外乎就是在操作数据库的时候。像MySQL,Oracle 这些主流的关系型数据库，也都提供的完整的事务实现。那消息队列为什么也需要事务呢？

其实在很多场景下，我们发消息这个过程，目的往往就是通知另外一个系统或模块去更新数据，`消息队列中的事务，主要解决的就是消息生产者和消息消费者的数据一致性问题。`

就以电商项目为例。订单系统创建订单后，发消息给购物车系统，将已下单的商品从购物车中删除，因为从购物车中删除已下单的商品这个步骤，并不是用户下单支付这个主要流程中的必需的步骤，使用消息队列来异步清除购物车是更加合理的设计。
![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq05.png)

对于订单系统来说，创建订单的过程中实际上是执行了2个步骤的操作：
- 1.在订单库中插入一条订单数据，创建订单；
- 2.发消息给消息队列，消息的内容就是刚刚创建的订单。

购物车系统订阅相应的主题，接受订单创建的消息，然后清理购物车，在购物车中删除订单中的商品。

在分布式系统总，上面提到的这些步骤，任何一个步骤都有可能失败，如果不做任何处理，那么就可能出现订单数据和购物车数据不一致的情况，例如：
- 创建了订单并没有清理购物车；
- 订单没创建成功，购物车里面的商品却被清掉了。

需要解决的问题可以总结为：在上述任一步骤都有可能失败的情况下，还要保证订单库和购物车库这两个库的数据的一致性。

对于购物车系统收到订单创建成功消息清理购物车这个操作来说，失败的处理比较简单，只要成功执行购物车清理后再提交消费确认即可，如果失败，由于没有提交消费确认，消息队列就会自动重试。

问题的关键点集中在订单系统，创建订单和发送消息这两个步骤要么都操作成功，要么都操作失败，不允许一个成功一个失败的情况出现。

### 什么是分布式事务

如果我们需要对若干数据进行更新操作，为了保证这些数据的完整性和一致性，我们希望这些更新操作`要么都成功，要么都失败`。至于更新的数据，不只局限于数据库中的数据，也可能是磁盘上的一个文件，也可以是远端的一个服务，或者以其他形式存储的数据。

一个严格意义的事务实现，应该具有4个属性：`原子性`、`一致性`、`隔离性`和`持久性`。（ACID）
- 原子性：是指一个事务的操作不可分割，要么失败，要么成功，不能有一般成功一半失败的情况。
- 一致性:是指这些数据在事务执行完成这个时间点之前，读到的一定是更新前的数据，之后读到的一定是更新后的数据，不应该存在一个时刻，让用户读到更新过程中的数据。
- 隔离性：是指一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对正在进行的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。
- 持久性：是指一个事务一旦提交，后续的其他操作和故障都不会对事务的结果产生任何影响。

大部分传统的单体关系型数据库都完整的实现了ACID,但是，对于分布式系统来说，严格的实现ACID这四个特性几乎是不可能的，或者是实现的代价太大。

目前大家所说的分布式事务，更多情况下，是在分布式系统中事物的不完整实现。在不同的应用场景中，有不同的实现，目的是通过一些妥协来解决方案。

在实际的应用中，比较常见的分布式事务实现由 `2PC(Two-phase Commit，也叫做二阶段提交)`、`TCC(Try-Confirm-Cancel)`和`事务消息`。每一种实现都有其特定的使用场景，也有各自的问题，都不是完美的解决方案。

事务消息使用的场景主要是那些需要`异步更新数据`，并且对`数据实时性要求不太高的场景`。比如之前的例子，创建订单之后，如果出现短暂的几秒，购物车中的商品被没有及时清空，也不是完全不可以接受的，只是最终购物车的数据和订单数据保持一致就可以了。

### 消息队列是如何实现分布式事务的

事务消息需要消息队列提供相应的功能才能实现，Kafka和RocketMQ都提供了事务相关的功能。

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq06.png)

首先，订单系统在消息队列中开启一个事务，然后订单系统给消息服务器发送一个`“半消息”`，这个半消息并不是说消息是不完整的，它包含的内容就是完整的消息内容，半消息和普通消息的唯一区别是，在事务提交之前，对于消费者来说，这个消息是不可见的。

半消息发送成功之后，订单系统就可以执行本地事务了，在订单库中创建一条订单记录，并提交订单库的数据库事务。然后根据本地事务的执行结果提交或回滚事务消息。如果订单创建成功，那就提交事务消息，购物车系统就可以消费到这条消息然后继续后续的流程；如果订单创建失败，那就回滚事务消息，购物车系统就不会收到这条消息。n那么就基本实现了“要么都成功，要么都失败”的一致性要求。

但是，如果仅仅只是这样做还是有问题没有解决。如果在第四步提交事务消息失败了怎么办？kafka和RocketMQ给出了不同的解决方法。

Kafka的解决方案比较简单粗暴，直接抛出异常，让用户自行解决，我们可以在业务代码中重试提交，直到提交成功，或者也可以在删除之前创建的订单进行补偿。

**RocketMQ中分布式事务实现**

在RocketMQ中的事务实现中，增加了事务反查的机制来解决事务消息提交失败的问题。如果Producer 也就是订单系统，在提交或者回滚事务时发生了网络异常，RocketMQ的Broker没有收到提交或者回滚的请求，Broker会定期去Producer上反查这个事务对应的本地事务的状态，然后根据反查的结果决定提交或者回滚这个事务。


为了支撑这个事务反查机制，业务代码需要实现一个反查本地事务状态的接口，告知RabbitMQ本地事务是成功还是失败的。

在上面的例子中，我们只需要根据消息中的订单ID，在订单库中查询这个订单是否存在即可，如果订单存在则返回成功，否则返回失败。RocketMQ会自动根据实物反查的结果提交或者回滚事务消息。

这个反查本地事务的实现，并不依赖于消息的发送方，也就是订单服务的某个实例节点上的任何数据。这种情况下，即使是发送事务消息的那个订单服务节点宕机了，RocketMQ依旧可以通过其他订单服务的节点进行反查，确保事务的完整性。

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/07.png)

参考 https://rocketmq.apache.org/docs/transaction-example/

## 五.如何保证消息不丢失
现在主流的消息队列产品都提供了非常完善的消息可靠性机制，完全可以做到在消息传递的过程中，即使网络中断或者硬件故障，也能确保消息的可靠传输，不丢失消息。

绝大部分丢消息的原因都是由于开发者不熟悉消息队列，没有正确的使用和配置消息队列导致的。虽然不同的消息队列提供的API不一样，相关的配置项也不同，但是在保证消息可靠性传递这方面，它们实现原理是一样的。

### 检测消息丢失的方法

一个IT基础设施比较完善的公司，一般都有分布式链路系统，使用类似的追踪系统可以很方便地追踪每一条消息。

`我们可以利用消息队列的有序性来验证是否有消息丢失`。原理非常简单，在Producer端，我们每发出的消息附加一个递增的序号，然后在Consumer端来检查这个序号的连续性。

如果没有消息丢失，Consumer收到消息的序号必然是递增的，或者说收到的消息，其中的序号必然是上一条消息的序号+1，如果检测到的序号不连续，就是丢失消息了。还可以通过确实的序号来确定丢失的是哪一条消息，方便进一步排查原因。

大多数的消息队列客户端都支持拦截器机制，可以利用这个拦截器机制，在Producer发送消息之前的拦截器将序号注入到消息中，在Consumer收到消息的拦截器中检测序号的连续性，这样实现的好处就是消息的检测代码不会入侵到业务代码中，待系统稳定后，可以方便将这部分检测的逻辑关闭或者删除。

如果是一个分布式系统中实现这个检测方法，需要注意以下几个问题：

- 想Kafka 和 RocketMQ 这样的消息队列，它是不保证在Topic上的严格顺序的，只能保证分区上的消息是有序的，所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。

如果系统中的 Producer是多实例的，有序并不好协调多个Producer之前的发送顺序，所以也需要每个Producer分别生成各自的消息序列，并且需要附加上Producer的标识，在Consumer端按照每个Producer分别来检测序号的连续性。

Consumer 实例的数量最好和分区的数量一致，做到Consumer和分区一一对应，这样会比较方便得在Consumer内检测消息序号的连续性。

### 确保消息的可靠传输

一条消息从生产到消费完成这个过程，可以划分为三个阶段：

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq07png)

- 生产阶段：在这个阶段，从消息在Producer创建出来，经过网络传输发送给Broker端。
- 存储阶段：在这个阶段，消息在Broker端存储，如果是集群，消息会在这个阶段复制到其他副本上。
- 消费阶段：在这个阶段，Consumer从Broker上拉取消息，经过网络传输发送到Consumer上。

**1.1 生产阶段**

在生产阶段，消息队列通过最常用的请求确认机制，来保证消息的可靠传输：当你的代码调用发消息的方法时，消息队列的客户端会把消息发送给Broker,Broker收到消息后，会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，完成了一次正常消息的发送。

只要Producer收到了Broker的确认响应，就可以保证消息在生产阶段不会丢失。有些消息队列在长时间没有收到发送确认响应后，会自动重试，如果重试再失败，就会以返回值或者异常的方式告知用户。

在编写发送消息的代码时，`正确处理返回值或捕获异常，就可以保证这个阶段的消息不会丢失`。

以Kafaka为例，如何可靠地发送消息：

```java
try {
    RecordMetadata metadata = producer.send(record).get();
    System.out.println(" 消息发送成功。");
} catch (Throwable e) {
    System.out.println(" 消息发送失败！");
    System.out.println(e);
}
```

异步发送时，则需要在回调方法里进行检查，很多丢失消息的原因，就是因为使用了异步发送，却没有在回调方法中检查发送结果。
```java
producer.send(record, (metadata, exception) -> {
    if (metadata != null) {
        System.out.println(" 消息发送成功。");
    } else {
        System.out.println(" 消息发送失败！");
        System.out.println(exception);
    }
});
```

**1.2 存储阶段**

在存储阶段正常的情况下，只要Broker在正常的运行，消息就不会丢失，但是如果Broker出现了故障，比如进程死掉或者服务器宕机了，还是可能会丢失消息的。

如果对消息测可靠性要求非常高，可以通过`配置Broker参数`来避免因为宕机丢失消息。
对于单个节点的Broker，需要配置Broker参数，在收到消息后，将消息写入磁盘再给Producer返回确认响应，这样即使宕机，由于消息已经写入磁盘，就不会丢失消息，恢复后还可以继续消费。例如，在RocketMQ中，需要将刷盘方式`flushDiskType`配置为`SYNC_FLUSH`同步刷盘。

如果Broker是由多个节点组成的集群，需要Broker集群配置为：至少将消息两个以上的节点，再给客户端发送确认响应。这样在某个Broker宕机时，其他Broker可以替代宕机的Broker，也不会发生消息丢失。

**1.3 消费阶段**

消费阶段采用的是和生产阶段类似的消息确认机制确保消息的可靠传递，客户端从Broker拉取消息后，执行用户的消费业务逻辑，成功后，才会给Broker发送消费确认响应。如果Broker没收到消费确认响应，下次拉消息的时候还会返回同一条消息，确保消息不会在网络传输中丢失，也不会因为客户端在执行消费逻辑的时候出错而导致消息丢失。

在编写消费代码时需注意：`不要在收到消息后立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。`

以消费RabbitMQ为例，如何实现一段可靠的消费代码：
```python
def callback(ch, method, properties, body):
    print(" [x] 收到消息 %r" % body)
    # 在这儿处理收到的消息
    database.save(body)
    print(" [x] 消费完成 ")
    # 完成消费业务逻辑后发送消费确认响应
    ch.basic_ack(delivery_tag = method.delivery_tag)
 
channel.basic_consume(queue='hello', on_message_callback=callback)
```

>在消费的回到方法callback中，正确的顺序是，先把消息存储到数据库，然后再发送消费确认响应，这样保存消息到数据库失败，就不会执行消费确认的代码，下次拉到的还是这条消息，知道消费成功。

**总结**

- 生产阶段：需要捕获消息发送的错误，并重发消息。
- 存储阶段：通过配置刷盘和复制相关的参数，让消息写到多个副本的磁盘上，来确保消息不会因为某个Broker宕机或者磁盘损坏而丢失。
- 消费阶段:需要在处理完所有的消费逻辑之后，再发送消费确认的响应。

## 六.如何处理消费过程中的重复消息

在消息传递过程中，如果出现传递失败的情况，发送方就会执行重试，重试过程中就可能会产生重复的消息。对使用消息队列的业务系统来说，如果没有对重复消息进行处理，就有可能会导致系统的数据出现错误。

### 消息重复的情况必然存在

在MQTT协议中，给出了三种传递消息时能够提供的服务质量标准，这三种服务质量从低到高依次是：
- **At most once**:至多一次。消息在传递时，最多会被送达一次。换个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些消息可靠性要求不高的监控场景使用，比如每分钟上报一次机房的温度，可以接受少量消息的丢失。
- **At least once**:至少一次。消息在传递时，至少会被送达。也就是说，不允许丢失消息，但是允许少量的重复消息。
- **Exactly once**:恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高等级。

>MQTT（消息队列遥测传输）是ISO标准（ISO/IEC PRF 20922）下基于发布/订阅范式的消息协议。它工作在TCP/IP协议族上，是为硬件性能低下的远程设备以及网络状况糟糕的情况下而设计的发布/订阅型消息协议，为此，它需要一个消息中间件 。

这个服务质量标准不仅适用于MQTT，对所有的消息队列都是适用的。我们现在常用的绝大部分消息队列提供的服务质量都是At least once,包括RabbitMQ,RocketMQ和kafka都是这样。也就是说消息队列很难保证消息不重复。

需要注意的是，Kafaka文档中表示Kafka是支持Exactly once的。但是，它和服务质量标准的Exactly once是不一样的，它是Kafka另外一个特性，Kafka中支持的事务也和我们通常意义上的事务有一定的差异。`在Kafka中支持的事务和Exactly once 主要是为了配合流计算使用的特性。`

### 用幂等性解决重复消息问题

>一般解决重复消息的办法是，在消费端，让我们消费消息的操作具备幂等性。

**对系统的影响：At least once + 幂等消费 = Exactly once**

实现幂等操作最好的方式就是：`从业务逻辑设计上入手，将消费的业务逻辑设计成具备幂等性的操作。`

集中常见的设计幂等操作的方法：

**1.利用数据库的唯一约束实现幂等**

举一个例子，每次转账100元，要实现对于每个转账单个账户只可以执行一次变更操作，在分布式系统中，这个限制实现的方法非常多，最简单的就是可以在数据库中新建一张转账流水表，这个表中有三个字段:转账单ID、账户ID以及变更金额，然后用`转账单ID和账户ID这两个字段联合起来创建一个唯一约束`，这样对于相同的转账单ID和账户ID,表里至多有一条数据。

这样我们的消费逻辑就可以变为：“在转账流水表中增加一条转账记录，然后再根据转账记录，异步操作更新用户余额。” 在转账流水表中增加一条转账记录这个操作中，由于我们在这个表中预先定义了“账户ID转账单ID”的唯一约束，对于同一个转账单同一个账户只能插入一条记录，后续重复的插入操作都会失败，这样就实现了一个幂等操作。我们只需要写一个SQL，正确的实现它就可以了。

基于这个思路，不光是可以使用关系型数据库，只要是支持类似“**INSERT IF NOT EXIST**”语义的存储系统都可以实现幂等。比如，`可以用 Redis 的 SETNX 命令来替代数据库中的唯一约束`，来实现消息幂等。

**2.为更新数据设置前置条件**

给数据变更设置一个前置条件，如果满足条件就更新数据，否则就拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。这样，重复执行这个数据时，由于第一次更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据库。

如果我们要更新的数据不是数值，或者要进行一个比较复杂的更新操作时，更加通用的方法是给你的数据增加一个版本号属性，每次更新数据前，比较当前数据的版本号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据之后可以把版本号+1，一样可以实现幂等更新。

**3.记录并检查操作**

还有一种通用性最强，适用范围最广的幂等性实现方法：记录并检查操作，也称为“Token机制或者GUID(全局唯一ID)机制”，实现的思路非常简单：`在执行数据更新操作之前，先检查一下是否执行过这个更新操作。`

具体的实现方法是，在发送消息是，给每条消息指定一个全局唯一的ID，消费时，先根据这个ID检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后把消费状态置为已消费。

在分布式系统中，这种方法其实是很难实现的。首先，给每一条消息指定一个全局唯一的ID就不是一件简单的事，方法有很多，但都不太好同时满足简单、高可用和高性能。更加麻烦的是，在“检查消费状态，然后更新数据并且设置消费状态”中，三个操作必须作为一组操作保证原子性，才能真正实现幂等。

比如说，对于同一条消息：“全局ID为8，操作为：给ID为666账户增加了100元”，有可能出现这样的情况：

- t0时刻：ConsumerA收到消息，检查消息执行状态，发现消息并未处理，开始执行“账户增加100元”；
- t1时刻：ConsumerB收到消息，检查消息执行状态，发现消息未处理过，因为这个时刻ConsumerA还未来得及更新消息执行状态。

这样就会导致账户被错误地增加两次100元，这是一个分布式系统中非常容易犯的错误。

对于这个问题，我们可以用事务来实现，也可以用锁来实现。

**思考**：为什么大部分的消息队列都选择只提供At least once 的质量，而不是级别更高的Exactly once 呢？

若消息队列实现了exactly once，会引发的问题可能有：

①消费端在pull消息时，需要检测此消息是否被消费，这个检测机制无疑会拉低消息消费的速度。可以预想到，随着消息的剧增，消费性能势必会急剧下降，导致消息积压；

②检查机制还需要业务端去配合实现，若一条消息长时间未返回ack，消息队列需要去回调看下消费结果（这个类似于事物消息的回查机制）。这样就会增加业务端的压力，与很多的未知因素。

## 七.消息积压了怎么处理

在消息队列的使用过程中，最常遇到的问题，就是消息积压的问题。消息积压的原因，一定是系统中某一个部分出现了性能问题，来不及处理上游发送的消息，才会导致消息积压。

### 1.优化性能来避免消息积压

在使用消息队列的系统中，对于性能的优化，主要体现在生产者和消费者这一收一发来个部分的业务逻辑中。对于消息队列本身的性能，作为使用者，不需要太关注，因为绝大多数使用消息队列的业务业务来说，消息队列本身的处理能力要远大于业务系统的处理能力。主流消息队列的单个节点，消息收发的性能可以达到每秒中处理几万至几十万条消息的水平，还可以`通过水平拓展Broker的实例数成倍地提升处理能力`。

而一般的业务系统需要处理的业务逻辑远比消息队列复杂，单个节点每秒可以处理几百到几千次的请求，已经可以算是性能非常好了。所以，对于消息队列的性能优化，我们更要关注的是，在消息收发两端，我们的业务代码怎么和消息队列相配合，达到一个最佳的性能。

**1.1 发送端性能优化**

发送端业务代码的处理性能，实际上和消息队列的关系不大，因为一般发送端都是先执行自己的业务逻辑，最后再发送消息。如果说，**你的代码发送消息的性能上不去，你需要优先检查一下，是不是发消息之前的业务逻辑耗时太多导致的**。

对于发送消息的业务逻辑，只需要注意**设置合适的并发和批量大小**，就可以达到很好的发送性能。

Producer 发送消息的过程，Producer发消息给Broker，Broker收到消息后返回确认响应，这是一次完整的交互。假设这一次的交互平均延时为1ms,把这 1ms 的时间分解开，它包括了下面这些步骤的耗时：

- 1.发送端准备数据、序列化消息、构造请求等逻辑的时间，也就是发送端在发送网络请求之前的耗时；
- 2.发送消息和返回响应在网络传输中的耗时；
- 3.Broker 处理消息的耗时

如果是单线程发送，每次只发送一条消息，那么每秒只能发送1000ms/1ms*1条/ms = 1000 条消息，这种情况下并不能发挥出消息队列的全部实力。

无论是增加每次发送消息的批量大小，还是增加并发，都能够成倍地提升性能。至于到底是选择批量发送还是增加并发，主要取决于发送端程序的业务性质。简单来说，这要能够满足性能要求，怎么实现方便就实现。

比如说，你的消息发送端是一个微服务，主要接收的是RPC请求处理的在线业务。很自然的，微服务在处理每次请求的时候，就在当前线程直接发送消息就可以了，因为所有RPC框架都是多线程支持多并发的，自然也就实现了并行发送消息。并且在线业务比较在意的是请求响应时延，选择批量发送必然会影响RPC服务的延时，这种情况，比较明智的方式就是通过并发来提升性能。

如果你的系统是一个离线分析系统，不关心时延，更加注重整个系统的吞吐量。发送端的数据都来自数据库，这种情况更适合批量发送，可以批量从数据库读取数据，然后批量发送数据，这样可以用少量的并发就可以获取非常高的吞吐量。

**1.2 消费端性能优化**

使用消息队列的时候，大部分的性能问题都出现在消费端，如果消费端消费的速度跟不上发送端生产消息的速度，就会造成消息的积压，如果这种性能倒挂的问题只是暂时的，那问题不大，只要消费端的性能恢复之后，超过发送端的性能，那积压的消息就可以逐渐被消化掉。

要是消费速度一直比生产速度慢，时间长了之后，整个系统就会出现问题，要么消息队列的存储被填满无法提供服务，要么消息丢失，对于整个系统来说就是严重故障。

所以，我们在设计系统的时候，一定要保证**消费端的消费性能能要高于生产端的发送性能**，这样的系统才能健康的持续运行。

消费端的性能优化除了优化消费业务逻辑以外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能。特别要注意的一点就是，在扩容Consumer的实例数量的同時，必須同步扩容主题中的分区（也叫队列）数量，确保Consumer的实例数和分区数量是相等的。如果Consumer 的实例数量超过分区数量，这样的扩容实际上是么有效果的，因为**对于消费者来说，在每个分区上实际上只支持单线程消费**。

常见的`错误的`解决消费慢的解决方案：
![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq11.png)

它收消息处理的业务逻辑可能会比较慢，也很难优化了，为了避免消息积压，在收到消息的OnMessage 方法中，不处理任何业务逻辑，把这个消息放到一个内存队列里面就返回了。然后它可以启动很多的业务线程，这些业务线程里面是真正处理消息的业务逻辑，这些线程从内存队列里取消息处理，这样它就解决了单个 Consumer 不能并行消费的问题。

这个方法是不是很完美地实现了并发消费？但是，`这是一个非常常见的错误方法!`
为什么会错误？因为会丢消息，如果收消息的节点发生宕机，在内存队列中还没来得及处理的这些消息就会丢失。

### 2.消息积压了该如何处理？

还有一种消息积压的情况就是，日常系统正常运转时，没有积压或者只有少量的积压很快就能消费掉。但是在某一时刻，突然就开始积压消息并且积压持续上涨。

导致突然积压的原因肯定是多种多样的，不同的系统、不同的情况有不同的原因，不能一概而论。但是，我们在排查消息积压的原因，是有一些相对固定而且比较有效的方法的。

能导致积压突然增加，最粗粒度的原因，只要两种：`要么是发送变快了，要么是消费变慢了`。

大部分的消息队列都内置了监控的功能，只要通过监控数据，很容易确定是哪种原因。如果是单位时间发送的消息增多，比如说是赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升消费性能。唯一的方法是通过`扩容消费端的实例数`来提升总体的消费能力。

如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将系统`降级`，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。

还有一种不太常见的情况，通过监控发现，无论是发送消息的速度还是消费消息的速度和原来没什么变化，这时候就需要检查一下消费端，是不是消费失败导致一条消息反复消费这种情况比较多，这种情况也会拖慢整个系统的消费速度。

如果监控到消费变慢了，需要检查消费实例，分析一下是什么原因导致消费变慢，优先检查一下日志是否有大量的消费错误，如果没有错误的话，可以通过打印堆栈信息，看一下消费线程是不是卡在什么地方不动了，比如触发了死锁或者卡在等待某些资源上了。

**总结**

优化消费端性能，预防消息积压的方法有两种，增加批量或者增加并发，在发送端这两种方法都可以使用，在消费端需要注意的是，增加并发需要同步扩容分区数量， 否则起不到效果。

对于系统发生消息积压的情况，需要先解决消息积压，再分析原因，毕竟保证系统的可用性是首先要解决的问题。快速解决积压的方法就是通过水平扩容增加 Consumer 的实例数量。

## 八.如何使用异步提升系统性能？

对于开发者来说，异步是一种程序设计的思想，使用异步模式设计的程序可以显著减少线程等待，从而在搞吞吐量的场景中，极大提升系统的整体性能，显著降低时延。

因此，像消息队列这种需要高吞吐量和超低时延的中间件系统，在其核心流程中，一定会大量采用异步设计思想。

### 异步设计如何提升系统性能？

假设我们要实现一个转账的微服务 Transfer(accountFrom,acciuntTo,amount),这个服务有三个参数：分别是转出账户、转入账户和转账金额。

实现过程比较简单，我们要从账户A 中转账100元到账户B 中。

- 1.先从A的账户中减去100元；
- 2.再给B的庄户加100元，转账完成。

对应的时序图：
![iamge](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq202007101544.jpg)

在这个实例中，我们调用了另外一个微服务 Add (account,amount),它的功能是给账户account增加金额amount,当amount为负值时，就是减扣相应的金额。

**1.同步实现的性能瓶颈**


首先我们看一下同时实现对应的伪代码：
```
Transfer(accountFrom, accountTo, amount) {
  // 先从 accountFrom 的账户中减去相应的钱数
  Add(accountFrom, -1 * amount)
  // 再把减去的钱数加到 accountTo 的账户中
  Add(accountTo, amount)
  return OK
}
```

上面的伪代码首先从accountFrom的账户中减去相应的签署，再把减去的钱数加到accountTo的账户中，这种同步实现是一种很自然的方式，简单直接。但是其性能如何呢？

假设微服务Add的平均响应时延时50ms，那么很容易就可以计算出我们实现的微服务Transfer的平均时延大约等于执行两次Add的时延，也就是100ms，那随着调用Transfer服务的请求越来越多，会出现什么情况呢？

在这种实现中，每处理一个请求需要耗时100ms，并在这100ms过程中是需要一个独占线程的，那么可以得出这么一个结论：每个线程每秒中最多可以处理10个请求。我们知道，每台计算机上的线程资源并不是无限的，假设我们使用的服务器同时打开的线程数量的上线是10000，可以计算出这台服务器上每秒中可以处理的请求上限是：10000（个线程）* 10（次请求每秒） = 100000次每秒。

如果请求速度超过这个值，那么请求就不能马上处理，只能阻塞或者排队，这时候Transfer服务的响应时延由100ms延长到了：排队的等待时延 + 处理时延（100ms）。也就是说，在大量请求的情况下，我们的微服务平均相应时延就长了。

这是不是已经到了这台服务器所能承受的极限了呢？其实远远没有，如果我们检测一下服务器的各项指标，会发现无论是CPU、内存、还是网卡流量或者是磁盘的IO都空闲的很，那我们Transfer服务中的那10000个线程在干什么呢？对，绝大部分线程都在等待服务Add服务返回结果。

也就是说，`采用同步实现的方式，这个服务器的所有线程大部分时间都没有在工作，而是都在等待`。

如果我们能减少或者避免这种无意义的等待，就可以大幅度提升服务的吞吐能力，从而提升服务的总体性能。

**2.采取异步实现解决等待问题**

实现同样的业务逻辑，可以采用异步的思想来解决这个问题：
```
TransferAsync(accountFrom, accountTo, amount, OnComplete()) {
  // 异步从 accountFrom 的账户中减去相应的钱数，然后调用 OnDebit 方法。
  AddAsync(accountFrom, -1 * amount, OnDebit(accountTo, amount, OnAllDone(OnComplete())))
}
// 扣减账户 accountFrom 完成后调用
OnDebit(accountTo, amount, OnAllDone(OnComplete())) {
  //  再异步把减去的钱数加到 accountTo 的账户中，然后执行 OnAllDone 方法
  AddAsync(accountTo, amount, OnAllDone(OnComplete()))
}
// 转入账户 accountTo 完成后调用
OnAllDone(OnComplete()) {
  OnComplete()
}
```

通过上面的代码可以发现，TransferAsync 服务比 Transfer 多了一个参数，并且这个参数传入的是一个回调方法 OnComplete()（虽然Java语言并不支持将方法作为方法参数传递，但是像JavaScript等很多语言都具有这样的特性，在Java语言中，也可以通过传入一个回调类的实例来变相实现类似的功能）。

这个TransferAsync() 方法的语义是：请帮我执行转账操作，当转账完成后，请调用OnComplete()方法。调用TransferAsync 的线程不必等待转账完成就可以立即返回了，待转账结束后，TransferService自然会调用OnComplete()方法来执行转账后续的工作。

异步的实现过程相对于同步来说，稍微有点复杂。我们先定义2个回调方法：

- OnDebit():扣减完成后调用地回调方法。
- OnAllDone():转入账户完成后调用的回调方法。

这个异步实现的语义相当于：

- 1.异步从 accountFrom 的账户中减去响应的钱数，然后调用OnDebit方法；
- 2.在OnDebit方法中，异步减去的钱数加到accountTp 的账户上，然后执行 OnAllDone 方法；
- 3.在OnAllDone 方法中，调用 OnComplete 方法。

绘制成时序图就是这样：

![image](https://dyzzz.oss-cn-beijing.aliyuncs.com/img/mq202007101748.jpg)

异步化实现后，整个流程的时序和同步实现是完全一样的，区别只是`在线程模型上由同步顺序调用改为了异步调用和回调机制`。

接下来我们分析一下异步实现的性能，由于流程的时序和同步实现是一样，在低请求数量的场景下，平均响应时延一样是 100ms。在超高请求数量场景下，异步的实现不再需要线程等待执行结果，只需要个位数量的线程，即可实现同步场景大量线程一样的吞吐量。

由于没有了线程的数量的限制，总体吞吐量上限会大大超过同步实现，并且在服务器 CPU、网络带宽资源达到极限之前，响应时延不会随着请求数量增加而显著升高，几乎可以一直保持约 100ms 的平均响应时延。

### 简单实用的异步框架：CompletebaleFuture

在实际开发中，我们可以使用异步框架或者响应式框架，来解决一些异步编程问题，简化开发。Java中比较常用的异步框架有Java8内置的CompleteableFuture 和 ReactiveX 的 [RxJava](https://github.com/ReactiveX/RxJava)

Java8 中新增了一个非常强大的用于异步编程的类：CompletableFuture，几乎囊括了我们在异步开发程序的大部分功能，使用CompletableFuture 很容易编写出优雅且易于维护的异步代码。

接下来，我们来看下，如果用CompletableFuture 实现的转账服务。

首先，我们用 CompletableFuture 定义2个微服务接口：

```Java
/**
 * 账户服务
 */
public interface AccountService {
    /**
     * 变更账户金额
     * @param account 账户 ID
     * @param amount 增加的金额，负值为减少
     */
    CompletableFuture<Void> add(int account, int amount);
}
```
```Java
/**
 * 转账服务
 */
public interface TransferService {
    /**
     * 异步转账服务
     * @param fromAccount 转出账户
     * @param toAccount 转入账户
     * @param amount 转账金额，单位分
     */
    CompletableFuture<Void> transfer(int fromAccount, int toAccount, int amount);
}
```
可以看出这两个接口定义的方法的返回类型都是一个带泛型的CompletableFeture。尖括号中的泛型类型就是真正方法需要返回的数据类型,这两个服务不需要返回数据，所以直接返回void就行。

然后来实现转账服务：

```Java
/**
 * 转账服务的实现
 */
public class TransferServiceImpl implements TransferService {
    @Inject
    private  AccountService accountService; // 使用依赖注入获取账户服务的实例
    @Override
    public CompletableFuture<Void> transfer(int fromAccount, int toAccount, int amount) {
      // 异步调用 add 方法从 fromAccount 扣减相应金额
      return accountService.add(fromAccount, -1 * amount)
      // 然后调用 add 方法给 toAccount 增加相应金额
      .thenCompose(v -> accountService.add(toAccount, amount));    
    }
}
```

在转账服务的实现类TransferServiceImpl 里面，先定义一个AccountService 实例，这个实例是从外部注入进来的。然后实现transfer（）方法的实现，先调用一次账户服务 accountService.add()方法从 fromAccount 扣减响应的金额，因为 add() 方法返回的就是一个 CompletableFeture 对象，可以用 CompletableFeture 的 thenCompose() 方法将下一次调用 accountService.add() 串联起来，实现异步依次调用两次账户服务完整转账。

客户端使用 CompletableFuture 也非常灵活，既可以同步调用，也可以异步调用。

```Java
public class Client {
    @Inject
    private TransferService transferService; // 使用依赖注入获取转账服务的实例
    private final static int A = 1000;
    private final static int B = 1001;
 
    public void syncInvoke() throws ExecutionException, InterruptedException {
        // 同步调用
        transferService.transfer(A, B, 100).get();
        System.out.println(" 转账完成！");
    }
 
    public void asyncInvoke() {
        // 异步调用
        transferService.transfer(A, B, 100)
                .thenRun(() -> System.out.println(" 转账完成！"));
    }
}
```

在调用异步方法获得返回值 CompletableFuture 对象后，既可以调用 CompletableFuture 的 get 方法，像调用同步方法那样等待调用的方法执行结束并获得返回值，也可以像异步回调的方式一样，调用 CompletableFuture 那些以 then 开头的一系列方法，为 CompletableFuture 定义异步方法结束之后的后续操作。比如像上面这个例子中，我们调用 thenRun() 方法，参数就是将转账完成打印在控台上这个操作，这样就可以实现在转账完成后，在控制台打印“转账完成！”了。

**小结**

简单来说，异步思想就是，当我们要执行一项比较耗时的操作时，不去等待操作结束，而是给这个操作一个命令：“当操作完成后，接下来去执行什么。”

使用异步编程模型，虽然并不能加快程序本身的速度，但是可以减少或者避免线程的等待，只用很少的线程就可以达到超高的吞吐能力。

同时我们也需要注意到异步模型的问题：相比于同步实现，异步实现的复杂度要大得多，代码的可读性和可维护性都会显著的下降。虽然使用一些异步框架可以在一定程度上简化异步开发，但是并不能解决异步模型高复杂度的问题。

异步性能虽好，但一定不能滥用，只有类似在像消息队列这种业务逻辑简单并奇瑞需要超高吞吐量的场景下，或者必须长时间等待资源的地方，才考虑使用一步模型。如果系统的业务逻辑比较复杂，在性能能够满足业务需求的情况下，采用符合人类自然的思路且易于开发和维护的同步模型是更加明智的选择。
